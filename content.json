{"meta":{"title":"Goblin' Blog","subtitle":"A Java Engineer's Technology Blog","description":"Java技术记录&分享","author":"Goblin","url":"https://shitianshuai1111.github.io","root":"/"},"posts":[{"tags":[{"name":"软件","slug":"软件","permalink":"https://shitianshuai1111.github.io/tags/%E8%BD%AF%E4%BB%B6/"},{"name":"破解","slug":"破解","permalink":"https://shitianshuai1111.github.io/tags/%E7%A0%B4%E8%A7%A3/"}],"title":"JetBrain全家桶破解","date":"2020/04/25","text":"链接: https://pan.baidu.com/s/15QvIdrdKpdDMys63rma45Q 密码: fr3o Jetbrains系列产品2020.1最新激活方法[持续更新]大家熟知Jetbrains的话应该知道：他们家的所有产品升级到2018.2.1及以上版本后，先前可用的注册服务器都失效了，无法激活升级到最新版本体验最新黑科技。 这次要送的这份礼就是： Jetbrains全系列产品2020.1及以下版本（理论上适用于目前所有新老版本）最新注册服务器（License Server）的破解，可使用它来激活你手头上的Jetbrains IDE，具体支持产品和版本见下文的列表。 传送门：链接: https://pan.baidu.com/s/15QvIdrdKpdDMys63rma45Q 密码: fr3o 具体使用方法已写在压缩包的 README.pdf / README.txt内。 （要个毛的readme，直接把jetbrains-agent-latest.zip拖进IDE就行了） 已更新v3.2.0, Build Date: 2020-04-10，支持2020.1。 在以下IDE版本测试可成功激活（v3.2.0）： IntelliJ IDEA 2020.1及以下 AppCode 2019.3.7及以下 CLion 2020.1及以下 DataGrip 2020.1及以下 GoLand 2020.1及以下 PhpStorm 2020.1及以下 PyCharm 2020.1及以下 Rider 2020.1.0及以下 RubyMine 2020.1及以下 WebStorm 2020.1及以下 有小部分网友（都是Windows系统）反馈看不到Helper的按钮，你直接敲回车啊！ 至于ReSharper，请务必试试这个方法：传送门！ 新的 agent license server：https://fls.jetbrains-agent.com（HTTP也可用） 插件的 Activation code，暂不在列表的试试 license server。 本jetbrains-agent自始至终都是免费使用，如果有你发现有人盗取牟利，请拒绝并不遗余力地在一切平台举报投诉他！ 下面是国际惯例： 本项目只做个人学习研究之用，不得用于商业用途！ 若资金允许，请点击链接购买正版，谢谢合作！ 学生凭学生证可免费申请正版授权！ 创业公司可5折购买正版授权！","permalink":"https://shitianshuai1111.github.io/2020/04/25/JetBrain%E5%85%A8%E5%AE%B6%E6%A1%B6%E7%A0%B4%E8%A7%A3/","photos":[]},{"tags":[{"name":"笔记","slug":"笔记","permalink":"https://shitianshuai1111.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"命令行","slug":"命令行","permalink":"https://shitianshuai1111.github.io/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C/"}],"title":"Mac启动各项服务 终端命令","date":"2020/03/31","text":"Mac如何启动各项服务一. Redisredis-server 启动服务端redis-cli 客户端测试连接 二. RabbitMQsudo rabbitmq-server 三. MongoDBmongod -dbpath /usr/local/Cellar/mongodb-community/data/db","permalink":"https://shitianshuai1111.github.io/2020/03/31/Mac%E5%90%AF%E5%8A%A8%E5%90%84%E9%A1%B9%E6%9C%8D%E5%8A%A1/","photos":[]},{"tags":[{"name":"干货","slug":"干货","permalink":"https://shitianshuai1111.github.io/tags/%E5%B9%B2%E8%B4%A7/"},{"name":"笔记","slug":"笔记","permalink":"https://shitianshuai1111.github.io/tags/%E7%AC%94%E8%AE%B0/"}],"title":"Docker怎么玩~","date":"2020/03/31","text":"一. Docker基础篇:Docker的三大要素: 镜像-只读的原本 类比java的类 容器-一个个在Docker中跑的程序(nginx, redis等) 类比java类创建出的实例 仓库-可以把打包好的镜像上传到DockerHub, 运维可以直接下载(国外的网站太慢, 用不到) 虚拟机和Docker的区别: CentOS/ Ubuntu基础镜像仅170MB 而虚拟机的镜像系统要4个G(同时模拟了硬件) docker(容器虚拟化技术) 虚拟机技术 操作系统 与宿主机共享, docker引擎调节 宿主机os上运行虚拟机os 储存大小 镜像小, 便于传输(Mb) 镜像大(G) 运行性能 几乎无额外性能损失 操作系统消耗额外cpu 移植性 轻便灵活 与虚拟化技术耦合 硬件亲和性 面向软件开发 面向运维 部署速度 秒级 分钟级(10s+) 开发/运维: DevOps 一次构建, 随处运行 Docker的架构图: 从远程Registry拉取到本地, 就是一个Images镜像, 这个镜像的实例就是一个Containers容器 镜像就是模板, 容器就是这个镜像的实例. 一个镜像可以创建很多容器. 可以把容器看成一个简易版的Linux环境, 和运行在其中的应用程序. 仓库是集中存放镜像文件的场所 Repository仓库和Registry仓库注册服务器是有区别的. 仓库注册服务器上往往存放着多个仓库, 每个仓库中又包含了多个镜像, 每个镜像有不同的标签(tag) 仓库又分为公开仓库和私有仓库. 两种形式, 世界最大公开仓库DockerHub, 国内的公开仓库 阿里云. Docker安装的官方文档: 安装就看他 https://docs.docker.com/install/linux/docker-ce/centos/ 阿里云镜像加速的配置文档: 配置阿里仓库就看他 https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors 专属加速地址 https://ld9eyi9w.mirror.aliyuncs.com Docker指令之helloworld: docker run hello-world先在本地找, hello-world的镜像 ->没有, 去远程拉取pulling 流程图: docker命令: 1. docker -version 版本信息2. docker info 详细信息3. docker --help 常用命令4. docker images 当前主机能运行的镜像模板 REPOSITORY: 镜像的仓库源 TAG: 版本 IMAGE ID: 镜像的唯一ID CREATED: 创建时间 SIZE : 大小5. docker search 去dockerhub查找(配置了镜像也是从dockerhub查询, 只是下载的时候去阿里云下载而已)6. docker pull 下载镜像7. docker rmi -f 镜像名 镜像名 镜像名... 删除镜像 清盘删除: docker rmi -f $(docker images -qa) $() 相当于 取出后面的docker images -qa的结果当做参数 tomcat为什么这么大呢? 8. docker run -it 470671670cac 9. docker ps 列出所有运行的容器10. exit 关闭容器并退出命令行 ctrl + p 再按 ctrl + q 不关闭容器, 先离开一会终端11. docker stop 停止容器 温柔关闭12. docker kill 直接杀死容器13. docker rm [-f] 容器号 删除容器 -f是强制删除(可删除正在运行的容器) docker rm -f $(docker ps -qa) 批量删除 或docker ps -qa | xargs docker rm linux命令, 管道符左边的结果当做参数传入右边的命令 docker run -d : 后台守护线程形式运行应用docker run -d centos /bin/sh -c \"while true;do echo hello zzyy;sleep 2; done\" 使用镜像centos以后台模式启动一个容器:$ docker run -d centos然后$ docker ps -a 进行查看, 会发现容器已经退出因为:Docker容器后台运行, 就必须有一个前台进程, 否则会自动退出这个是Docker的机制问题:比如nginx 我们配置启动服务只需要启动响应的service即可, 例如service nginx start但是这样 nginx为后台进程模式运行, 就会docker前台没有对应运行的应用.这样容器后台一启动, 就会立即自杀, 因为觉得自己没事做了.所以: 要将后台运行的程序以前台进程的形式运行 docker run -it centos /bin/bash 后面的 bin/bash的作用 (https://www.cnblogs.com/Guhongying/p/10894434.html) 首先，docker run -it centos 的意思是，为centos这个镜像创建一个容器， -i和-t这两个参数的作用是，为该docker创建一个伪终端，这样就可以进入到容器的交互模式？（也就是直接进入到容器里面）后面的/bin/bash的作用是表示载入容器后运行bash ,docker中必须要保持一个进程的运行，要不然整个容器启动后就会马上kill itself，这样当你使用docker ps 查看启动的容器时，就会发现你刚刚创建的那个容器并不在已启动的容器队列中。这个/bin/bash就表示启动容器后启动bash。 14. docker logs [参数] 容器id 查看日志 -f 跟随最新日志打印 -t 加入时间戳 --tail 显示最后多少条eg: docker logs -t -f --tail 3 7e0b062af691 15. docker top 容器id 查看容器内运行的进程16. docker inspect 容器id 查看容器的细节 比如: [ { \"Id\": \"7e0b062af6916144a33118a1\", \"Created\": \"2020-03-27T05:21:24.424453733Z\", \"Path\": \"/bin/sh\", \"Args\": [ \"-c\", \"while true;do echo hello zzyy;sleep 2; done\" ], \"State\": { \"Status\": \"running\", \"Running\": true, \"Paused\": false, \"Restarting\": false, \"OOMKilled\": false, \"Dead\": false, \"Pid\": 16750, \"ExitCode\": 0, \"Error\": \"\", \"StartedAt\": \"2020-03-27T05:21:24.799995316Z\", \"FinishedAt\": \"0001-01-01T00:00:00Z\" }, \"Image\": \"sha256:...\", \"ResolvConfPath\": \"\", \"HostnamePath\": \"\", \"HostsPath\": \"\", \"LogPath\": \"\", \"Name\": \"/crazy_fermi\", \"RestartCount\": 0, \"Driver\": \"overlay2\", \"Platform\": \"linux\", \"MountLabel\": \"\", \"ProcessLabel\": \"\", \"AppArmorProfile\": \"\", \"ExecIDs\": null, \"HostConfig\": { \"Binds\": null, \"ContainerIDFile\": \"\", \"LogConfig\": { \"Type\": \"json-file\", \"Config\": {} }, \"NetworkMode\": \"default\", \"PortBindings\": {}, \"RestartPolicy\": { \"Name\": \"no\", \"MaximumRetryCount\": 0 }, \"AutoRemove\": false, \"VolumeDriver\": \"\", \"VolumesFrom\": null, \"CapAdd\": null, \"CapDrop\": null, \"Capabilities\": null, \"Dns\": [], \"DnsOptions\": [], \"DnsSearch\": [], \"ExtraHosts\": null, \"GroupAdd\": null, \"IpcMode\": \"private\", \"Cgroup\": \"\", \"Links\": null, \"OomScoreAdj\": 0, \"PidMode\": \"\", \"Privileged\": false, \"PublishAllPorts\": false, \"ReadonlyRootfs\": false, \"SecurityOpt\": null, \"UTSMode\": \"\", \"UsernsMode\": \"\", \"ShmSize\": 67108864, \"Runtime\": \"runc\", \"ConsoleSize\": [ 0, 0 ], \"Isolation\": \"\", \"CpuShares\": 0, \"Memory\": 0, \"NanoCpus\": 0, \"CgroupParent\": \"\", \"BlkioWeight\": 0, \"BlkioWeightDevice\": [], \"BlkioDeviceReadBps\": null, \"BlkioDeviceWriteBps\": null, \"BlkioDeviceReadIOps\": null, \"BlkioDeviceWriteIOps\": null, \"CpuPeriod\": 0, \"CpuQuota\": 0, \"CpuRealtimePeriod\": 0, \"CpuRealtimeRuntime\": 0, \"CpusetCpus\": \"\", \"CpusetMems\": \"\", \"Devices\": [], \"DeviceCgroupRules\": null, \"DeviceRequests\": null, \"KernelMemory\": 0, \"KernelMemoryTCP\": 0, \"MemoryReservation\": 0, \"MemorySwap\": 0, \"MemorySwappiness\": null, \"OomKillDisable\": false, \"PidsLimit\": null, \"Ulimits\": null, \"CpuCount\": 0, \"CpuPercent\": 0, \"IOMaximumIOps\": 0, \"IOMaximumBandwidth\": 0, \"MaskedPaths\": [ \"/proc/asound\", \"/proc/acpi\", \"/proc/kcore\", \"/proc/keys\", \"/proc/latency_stats\", \"/proc/timer_list\", \"/proc/timer_stats\", \"/proc/sched_debug\", \"/proc/scsi\", \"/sys/firmware\" ], \"ReadonlyPaths\": [ \"/proc/bus\", \"/proc/fs\", \"/proc/irq\", \"/proc/sys\", \"/proc/sysrq-trigger\" ] }, \"GraphDriver\": { \"Data\": { \"LowerDir\": \"\", \"MergedDir\": \"\", \"UpperDir\": \"\", \"WorkDir\": \"\" }, \"Name\": \"overlay2\" }, \"Mounts\": [], \"Config\": { \"Hostname\": \"7e0b062af691\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/local/\" ], \"Cmd\": [ \"/bin/sh\", \"-c\", \"while true;do ech\" ], \"Image\": \"centos\", \"Volumes\": null, \"WorkingDir\": \"\", \"Entrypoint\": null, \"OnBuild\": null, \"Labels\": { \"org.label-schema.build-date\": \"20200114\", \"org.label-schema.license\": \"GPLv2\", \"org.label-schema.name\": \"CentOS Base Image\", \"org.label-schema.schema-version\": \"1.0\", \"org.label-schema.vendor\": \"CentOS\", \"org.opencontainers.image.created\": \"2020-01-\", \"org.opencontainers.image.licenses\": \"GPL-2.0-only\", \"org.opencontainers.image.title\": \"CentOS Base Image\", \"org.opencontainers.image.vendor\": \"CentOS\" } }, \"NetworkSettings\": { \"Bridge\": \"\", \"SandboxID\": \"3459bdd5aa27c479a87\", \"HairpinMode\": false, \"LinkLocalIPv6Address\": \"\", \"LinkLocalIPv6PrefixLen\": 0, \"Ports\": {}, \"SandboxKey\": \"/var/run/docker/netns/3459bdd5aa27\", \"SecondaryIPAddresses\": null, \"SecondaryIPv6Addresses\": null, \"EndpointID\": \"e519bb72809ee6f974029\", \"Gateway\": \"172.18.0.1\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"IPAddress\": \"172.18.0.2\", \"IPPrefixLen\": 16, \"IPv6Gateway\": \"\", \"MacAddress\": \"02:42:ac:12:00:02\", \"Networks\": { \"bridge\": { \"IPAMConfig\": null, \"Links\": null, \"Aliases\": null, \"NetworkID\": \"126cf7e01e7d170ed\", \"EndpointID\": \"e519bb728\", \"Gateway\": \"172.18.0.1\", \"IPAddress\": \"172.18.0.2\", \"IPPrefixLen\": 16, \"IPv6Gateway\": \"\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"MacAddress\": \"02:42:ac:12:00:02\", \"DriverOpts\": null } } } }] 17. docker attach 容器id 进入正在运行的容器并以命令行进行交互 直接进入容器启动命令的终端, 不做任何事 docker exec -it 容器id [/bin/bash ...] 在容器外执行, 既可以进去干, 还可以打开新进程(直接操作 隔山打牛的效果) 18. docker cp 容器id:容器内路径 目的主机路径 拷贝容器内文件到主机上 二. Docker高级篇 Docker镜像是什么: 轻量级的可执行的独立软件包, 用来打包软件运行环境和基于运行环境开发的软件, 它包含某个软件所需的所有内容, 包括代码, 运行时库, 环境变量, 和配置文件 UnionFS联合文件系统: 分层的轻量级高性能的文件系统. Docker镜像加载原理: docker镜像实际上由一层层的文件系统组成, bootfs: 主要包含bootloader和kernel, bootloader主要是引导加载kernel, linux刚启动时会加载bootfs文件系统, 在docker镜像的最底层是bootfs, 当boot加载完成后整个内核就都在内存中了, 此时内存的使用权已由bootfs转交给内核, 此时系统也会卸载bootfs rootfs: 在bootfs上, 包含的就是典型linux系统中的/dev, /proc, /bin等标准目录和文档, rootfs就是不同操作系统的发行版, 比如ubuntu centos等. tomcat 比centos还大的原因 docker采用分层镜像的原因: 共享资源 多个镜像都从相同的base镜像构建而来, 这样每个镜像的每一层都可被共享. docker的镜像都是只读的, 当容器启动时, 一个新的可写层被加载到 镜像的顶部, 这一层 通常被成为容器层, 容器层之下的都叫镜像层. docker 的commit 我们对一个源镜像, 进行了自定义的修改和配置后, 得到了我们专属的容器, 那么怎么把这个容器分享给他人, 使得他人启动这个容器和我们启动这个容器达到一样的效果呢? 这里就可以用commit命令. docker commit -a=\"goblin\" -m=\"my images\" 78sd7f8 mytomcat:v1.0 -a: author 作者 -m: 容器信息 要制作镜像的容器id 新镜像的名字:Tag(版本) docker容器数据卷: 当我们关闭容器后, 容器内的数据就没了, 那么我们关闭容器时, 需要对容器内产生的数据进行持久化. 这个要持久的数据就是数据卷. k将运用与运行的环境打包形成容器运行, 运行可以伴随着容器, 但是我们对数据的要求希望是持久化的 容器之间希望有可能共享数据 Docker容器产生数据, 如果不通过docker commit生成新的镜像, 使得数据作为镜像一部分保存下来, 那么当容器删除后, 数据也就没了. 为了能保存数据在docker中, 我们使用卷 目的就是: 持久化和数据共享 @1: 可以使用命令行 1. 在容器上建立文件夹挂载到主机上, 二者实时共享, 均可读写docker run -it -v /myDataVolumn:/dataVolumnContainer 镜像名2. 将容器上的文件夹/dataVolumnContainer(绝对路径)挂载到主机的/myDataVolumn, 容器只读: 容器只能查看主机传给他的文件, 自己不能写操作docker run -it -v /myDataVolumn:/dataVolumnContainer:ro 镜像名 (readonly) @2. 通过dockerfile dockerfile是对镜像 源码级 的描述,","permalink":"https://shitianshuai1111.github.io/2020/03/31/Docker%E7%9A%84%E7%94%A8%E6%B3%95/","photos":[]},{"tags":[],"title":"Git指令","date":"2020/03/30","text":"Git 从jd-dev拉取代码 git clone -b jd-dev http://192.168.8.134/neuhive-silver/neuhive-silver-platform.git 切换分支 git checkout -b newIssues 拉取jd-dev代码覆盖本地 git reset --hard orgin/jd-dev 添加, 提交, 推送 git add .git commit -m '#issuesName'git push --set-upstream orgin issuesName New Merge Request","permalink":"https://shitianshuai1111.github.io/2020/03/30/Git%E6%8C%87%E4%BB%A4/","photos":[]},{"tags":[{"name":"干货","slug":"干货","permalink":"https://shitianshuai1111.github.io/tags/%E5%B9%B2%E8%B4%A7/"},{"name":"笔记","slug":"笔记","permalink":"https://shitianshuai1111.github.io/tags/%E7%AC%94%E8%AE%B0/"}],"title":"Linux01-概述&环境搭建","date":"2017/06/29","text":"Linux系统 基于CentOS7 一. 入门概述 why linux? 二. 环境搭建三. Linux系统 开机登录 开机会启动许多程序。它们在Windows叫做”服务”（service），在Linux就叫做”守护进程”（daemon）。 开机成功后，它会显示一个文本登录界面，这个界面就是我们经常看到的登录界面，在这个登录界面中会提示用户输入用户名，而用户输入的用户将作为参数传给login程序来验证用户的身份，密码是不显示的，输完回车即可！ 一般来说，用户的登录方式有三种： 命令行登录 ssh登录 图形界面登录 最高权限账户为 root，可以操作一切！ 关机 在linux领域内大多用在服务器上，很少遇到关机的操作。毕竟服务器上跑一个服务是永无止境的，除非特殊情况下，不得已才会关机。 关机指令为：shutdown sync # 将数据由内存同步到硬盘中。shutdown # 关机指令，你可以man shutdown 来看一下帮助文档。例如你可以运行如下命令关机：shutdown –h 10 # 这个命令告诉大家，计算机将在10分钟后关机shutdown –h now # 立马关机shutdown –h 20:25 # 系统会在今天20:25关机shutdown –h +10 # 十分钟后关机shutdown –r now # 系统立马重启shutdown –r +10 # 系统十分钟后重启reboot # 就是重启，等同于 shutdown –r nowhalt # 关闭系统，等同于shutdown –h now 和 poweroff 最后总结一下，不管是重启系统还是关闭系统，首先要运行 sync 命令，把内存中的数据写到磁盘中。 系统目录结构 Linux的根节点是 /, 所有的资源都挂载在根节点下 以下是对这些目录的解释： /bin：bin是Binary的缩写, 这个目录存放着最经常使用的命令。 /boot： 这里存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件。 /dev ： dev是Device(设备)的缩写, 存放的是Linux的外部设备，在Linux中访问设备的方式和访问文件的方式是相同的。 /etc： 这个目录用来存放所有的系统管理所需要的配置文件和子目录。 /home：用户的主目录，在Linux中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。 /lib：这个目录里存放着系统最基本的动态连接共享库，其作用类似于Windows里的DLL文件。 /lost+found：这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。 /media：linux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，linux会把识别的设备挂载到这个目录下。 /mnt：系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。 /opt：这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。 /proc：这个目录是一个虚拟的目录，它是系统内存的映射，我们可以通过直接访问这个目录来获取系统信息。 /root：该目录为系统管理员，也称作超级权限者的用户主目录。 /sbin：s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序。 /srv：该目录存放一些服务启动之后需要提取的数据。 /sys：这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统 sysfs 。 /tmp：这个目录是用来存放一些临时文件的。 /usr：这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似于windows下的program files目录。 /usr/bin： 系统用户使用的应用程序。 /usr/sbin： 超级用户使用的比较高级的管理程序和系统守护程序。 /usr/src： 内核源代码默认的放置目录。 /var：这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。 /run：是一个临时文件系统，存储系统启动以来的信息。当系统重启时，这个目录下的文件应该被删掉或清除。 #Linux02-常用的基本命令（必掌握） ##一. 目录管理 绝对路径和相对路径 我们知道Linux的目录结构为树状结构，最顶级的目录为根目录 /。 其他目录通过挂载可以将它们添加到树中，通过解除挂载可以移除它们。 在开始本教程前我们需要先知道什么是绝对路径与相对路径。 绝对路径： 路径的写法，由根目录 / 写起，例如：/usr/share/doc 这个目录。 相对路径： 路径的写法，不是由 / 写起，例如由 /usr/share/doc 要到 /usr/share/man 底下时，可以写成：cd ../man 这就是相对路径的写法啦！ 处理目录的常用命令 接下来我们就来看几个常见的处理目录的命令吧： ls: 列出目录 cd：切换目录 pwd：显示目前的目录 mkdir：创建一个新的目录 (makedir) rmdir：删除一个空的目录 cp: 复制文件或目录 (copy) rm: 移除文件或目录 (remove) mv: 移动文件与目录，或修改文件与目录的名称 (move) 你可以使用 man [命令] 来查看各个命令的使用文档，如 ：man cp。 ls （列出目录） 在Linux系统当中， ls 命令可能是最常被运行的。 语法： [root@www ~]# ls [-aAdfFhilnrRSt] 目录名称 选项与参数： -a ：全部的文件，连同隐藏文件( 开头为 . 的文件) 一起列出来(常用) -l ：长数据串列出，包含文件的属性与权限等等数据；(常用) 将目录下的所有文件列出来(含属性与隐藏档) [root@www ~]# ls -al ~ cd （切换目录） cd是Change Directory的缩写，这是用来变换工作目录的命令。 语法： cd [相对路径或绝对路径] 测试： # 切换到用户目录下[root@kuangshen /]# cd home # 使用 mkdir 命令创建 kuangstudy 目录[root@kuangshen home]# mkdir kuangstudy# 进入 kuangstudy 目录[root@kuangshen home]# cd kuangstudy# 回到上一级[root@kuangshen kuangstudy]# cd ..# 回到根目录[root@kuangshen kuangstudy]# cd /# 表示回到自己的家目录，亦即是 /root 这个目录[root@kuangshen kuangstudy]# cd ~ 接下来大家多操作几次应该就可以很好的理解 cd 命令的。 pwd ( 显示目前所在的目录 ) pwd 是 Print Working Directory 的缩写，也就是显示目前所在目录的命令。 [root@kuangshen kuangstudy]#pwd [-P] 选项与参数：-P ：显示出确实的路径，而非使用连接(link) 路径。 测试： # 单纯显示出目前的工作目录[root@kuangshen ~]# pwd/root# 如果是链接，要显示真实地址，可以使用 -P参数[root@kuangshen /]# cd bin[root@kuangshen bin]# pwd -P/usr/bin mkdir （创建新目录） 如果想要创建新的目录的话，那么就使用mkdir (make directory)吧。 mkdir [-mp] 目录名称 选项与参数： -m ：配置文件的权限喔！直接配置，不需要看默认权限 (umask) 的脸色～ -p ：帮助你直接将所需要的目录(包含上一级目录)递归创建起来！ 测试： # 进入我们用户目录下[root@kuangshen /]# cd /home# 创建一个 test 文件夹[root@kuangshen home]# mkdir test# 创建多层级目录[root@kuangshen home]# mkdir test1/test2/test3/test4mkdir: cannot create directory ‘test1/test2/test3/test4’:No such file or directory # f1 从上面的结果中可以看出，硬连接文件 f2 与原文件 f1 的 inode 节点相同，均为 397247，然而符号连接文件的 inode 节点不同。 # echo 字符串输出 >> f1 输出到 f1文件[root@kuangshen home]# echo \"I am f1 file\" >>f1[root@kuangshen home]# cat f1I am f1 file[root@kuangshen home]# cat f2I am f1 file[root@kuangshen home]# cat f3I am f1 file[root@kuangshen home]# rm -f f1[root@kuangshen home]# cat f2I am f1 file[root@kuangshen home]# cat f3cat: f3: No such file or directory 通过上面的测试可以看出：当删除原始文件 f1 后，硬连接 f2 不受影响，但是符号连接 f1 文件无效； 依此您可以做一些相关的测试，可以得到以下全部结论： 删除符号连接f3,对f1,f2无影响； 删除硬连接f2，对f1,f3也无影响； 删除原文件f1，对硬连接f2没有影响，导致符号连接f3失效； 同时删除原文件f1,硬连接f2，整个文件会真正的被删除。 #Linux03-Vim使用及账号用户管理 什么是Vim编辑器 Vim是从 vi 发展出来的一个文本编辑器。代码补完、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。 简单的来说， vi 是老式的字处理器，不过功能已经很齐全了，但是还是有可以进步的地方。 vim 则可以说是程序开发者的一项很好用的工具。 所有的 Unix Like 系统都会内建 vi 文书编辑器，其他的文书编辑器则不一定会存在。 连 vim 的官方网站 (http://www.vim.org) 自己也说 vim 是一个程序开发工具而不是文字处理软件。 vim 键盘图： 三种使用模式 基本上 vi/vim 共分为三种模式，分别是命令模式（Command mode），输入模式（Insert mode）和底线命令模式（Last line mode）。这三种模式的作用分别是： 命令模式： 用户刚刚启动 vi/vim，便进入了命令模式。 此状态下敲击键盘动作会被Vim识别为命令，而非输入字符。比如我们此时按下i，并不会输入一个字符，i被当作了一个命令。 以下是常用的几个命令： i 切换到输入模式，以输入字符。 x 删除当前光标所在处的字符。 : 切换到底线命令模式，以在最底一行输入命令。 若想要编辑文本：启动Vim，进入了命令模式，按下i，切换到输入模式。 命令模式只有一些最基本的命令，因此仍要依靠底线命令模式输入更多命令。 输入模式： 在命令模式下按下i就进入了输入模式。 在输入模式中，可以使用以下按键： 字符按键以及Shift组合，输入字符 ENTER，回车键，换行 BACK SPACE，退格键，删除光标前一个字符 DEL，删除键，删除光标后一个字符 方向键，在文本中移动光标 HOME/END，移动光标到行首/行尾 Page Up/Page Down，上/下翻页 Insert，切换光标为输入/替换模式，光标将变成竖线/下划线 ESC，退出输入模式，切换到命令模式 底线命令模式 在命令模式下按下:（英文冒号）就进入了底线命令模式。 底线命令模式可以输入单个或多个字符的命令，可用的命令非常多。 在底线命令模式中，基本的命令有（已经省略了冒号）： q 退出程序 w 保存文件 按ESC键可随时退出底线命令模式。 简单的说，我们可以将这三个模式想成底下的图标来表示： 上手体验一下，在home目录下测试 如果你想要使用 vi 来建立一个名为 kuangstudy.txt 的文件时，你可以这样做： [root@kuangshen home]# vim kuangstudy.txt 然后就会进入文件 按下 i 进入输入模式(也称为编辑模式)，开始编辑文字 在一般模式之中，只要按下 i, o, a 等字符就可以进入输入模式了！ 在编辑模式当中，你可以发现在左下角状态栏中会出现 –INSERT- 的字样，那就是可以输入任意字符的提示。 这个时候，键盘上除了 Esc 这个按键之外，其他的按键都可以视作为一般的输入按钮了，所以你可以进行任何的编辑。 按下 ESC 按钮回到一般模式 好了，假设我已经按照上面的样式给他编辑完毕了，那么应该要如何退出呢？是的！没错！就是给他按下 Esc 这个按钮即可！马上你就会发现画面左下角的 – INSERT – 不见了！ 在一般模式中按下 :wq 储存后离开 vim！ OK! 这样我们就成功创建了一个 kuangstudy.txt 的文件。 Vim 按键说明 除了上面简易范例的 i, Esc, :wq 之外，其实 vim 还有非常多的按键可以使用。 第一部分：一般模式可用的光标移动、复制粘贴、搜索替换等 移动光标的方法 h 或 向左箭头键(←) 光标向左移动一个字符 j 或 向下箭头键(↓) 光标向下移动一个字符 k 或 向上箭头键(↑) 光标向上移动一个字符 l 或 向右箭头键(→) 光标向右移动一个字符 [Ctrl] + [f] 屏幕『向下』移动一页，相当于 [Page Down]按键 (常用) [Ctrl] + [b] 屏幕『向上』移动一页，相当于 [Page Up] 按键 (常用) [Ctrl] + [d] 屏幕『向下』移动半页 [Ctrl] + [u] 屏幕『向上』移动半页 + 光标移动到非空格符的下一行 - 光标移动到非空格符的上一行 n< space> 那个 n 表示『数字』，例如 20 。按下数字后再按空格键，光标会向右移动这一行的 n 个字符。 0 或功能键[Home] 这是数字『 0 』：移动到这一行的最前面字符处 (常用) $ 或功能键[End] 移动到这一行的最后面字符处(常用) H 光标移动到这个屏幕的最上方那一行的第一个字符 M 光标移动到这个屏幕的中央那一行的第一个字符 L 光标移动到这个屏幕的最下方那一行的第一个字符 G 移动到这个档案的最后一行(常用) nG n 为数字。移动到这个档案的第 n 行。例如 20G 则会移动到这个档案的第 20 行(可配合 :set nu) gg 移动到这个档案的第一行，相当于 1G 啊！(常用) n< Enter> n 为数字。光标向下移动 n 行(常用) 搜索替换 /word 向光标之下寻找一个名称为 word 的字符串。例如要在档案内搜寻 vbird 这个字符串，就输入 /vbird 即可！(常用) ?word 向光标之上寻找一个字符串名称为 word 的字符串。 n 这个 n 是英文按键。代表重复前一个搜寻的动作。举例来说， 如果刚刚我们执行 /vbird 去向下搜寻 vbird 这个字符串，则按下 n 后，会向下继续搜寻下一个名称为 vbird 的字符串。如果是执行 ?vbird 的话，那么按下 n 则会向上继续搜寻名称为 vbird 的字符串！ N 这个 N 是英文按键。与 n 刚好相反，为『反向』进行前一个搜寻动作。例如 /vbird 后，按下 N 则表示『向上』搜寻 vbird 。 删除、复制与粘贴 x, X 在一行字当中，x 为向后删除一个字符 (相当于 [del] 按键)， X 为向前删除一个字符(相当于 [backspace] 亦即是退格键) (常用) nx n 为数字，连续向后删除 n 个字符。举例来说，我要连续删除 10 个字符， 『10x』。 dd 删除游标所在的那一整行(常用) ndd n 为数字。删除光标所在的向下 n 行，例如 20dd 则是删除 20 行 (常用) d1G 删除光标所在到第一行的所有数据 dG 删除光标所在到最后一行的所有数据 d$ 删除游标所在处，到该行的最后一个字符 d0 那个是数字的 0 ，删除游标所在处，到该行的最前面一个字符 yy 复制游标所在的那一行(常用) nyy n 为数字。复制光标所在的向下 n 行，例如 20yy 则是复制 20 行(常用) y1G 复制游标所在行到第一行的所有数据 yG 复制游标所在行到最后一行的所有数据 y0 复制光标所在的那个字符到该行行首的所有数据 y$ 复制光标所在的那个字符到该行行尾的所有数据 p, P p 为将已复制的数据在光标下一行贴上，P 则为贴在游标上一行！举例来说，我目前光标在第 20 行，且已经复制了 10 行数据。则按下 p 后， 那 10 行数据会贴在原本的 20 行之后，亦即由 21 行开始贴。但如果是按下 P 呢？那么原本的第 20 行会被推到变成 30 行。(常用) J 将光标所在行与下一行的数据结合成同一行 c 重复删除多个数据，例如向下删除 10 行，[ 10cj ] u 复原前一个动作。(常用) [Ctrl]+r 重做上一个动作。(常用) 第二部分：一般模式切换到编辑模式的可用的按钮说明 进入输入或取代的编辑模式 i, I 进入输入模式(Insert mode)：i 为『从目前光标所在处输入』， I 为『在目前所在行的第一个非空格符处开始输入』。(常用) a, A 进入输入模式(Insert mode)：a 为『从目前光标所在的下一个字符处开始输入』， A 为『从光标所在行的最后一个字符处开始输入』。(常用) o, O 进入输入模式(Insert mode)：这是英文字母 o 的大小写。o 为『在目前光标所在的下一行处输入新的一行』；O 为在目前光标所在处的上一行输入新的一行！(常用) r, R 进入取代模式(Replace mode)：r 只会取代光标所在的那一个字符一次；R会一直取代光标所在的文字，直到按下 ESC 为止；(常用) [Esc] 退出编辑模式，回到一般模式中(常用) 第三部分：一般模式切换到指令行模式的可用的按钮说明 指令行的储存、离开等指令 :w 将编辑的数据写入硬盘档案中(常用) :w! 若文件属性为『只读』时，强制写入该档案。不过，到底能不能写入， 还是跟你对该档案的档案权限有关啊！ :q 离开 vi (常用) :q! 若曾修改过档案，又不想储存，使用 ! 为强制离开不储存档案。 注意一下啊，那个惊叹号 (!) 在 vi 当中，常常具有『强制』的意思～ :wq 储存后离开，若为 :wq! 则为强制储存后离开 (常用) ZZ 这是大写的 Z 喔！若档案没有更动，则不储存离开，若档案已经被更动过，则储存后离开！ :w [filename] 将编辑的数据储存成另一个档案（类似另存新档） :r [filename] 在编辑的数据中，读入另一个档案的数据。亦即将 『filename』 这个档案内容加到游标所在行后面 :n1,n2 w [filename] 将 n1 到 n2 的内容储存成 filename 这个档案。 :! command 暂时离开 vi 到指令行模式下执行 command 的显示结果！例如 『:! ls /home』即可在 vi 当中看 /home 底下以 ls 输出的档案信息！ :set nu 显示行号，设定之后，会在每一行的前缀显示该行的行号 :set nonu 与 set nu 相反，为取消行号！ 账号管理 简介 Linux系统是一个多用户多任务的分时操作系统，任何一个要使用系统资源的用户，都必须首先向系统管理员申请一个账号，然后以这个账号的身份进入系统。 用户的账号一方面可以帮助系统管理员对使用系统的用户进行跟踪，并控制他们对系统资源的访问；另一方面也可以帮助用户组织文件，并为用户提供安全性保护。 每个用户账号都拥有一个唯一的用户名和各自的口令。 用户在登录时键入正确的用户名和口令后，就能够进入系统和自己的主目录。 实现用户账号的管理，要完成的工作主要有如下几个方面： 用户账号的添加、删除与修改。 用户口令的管理。 用户组的管理。 用户账号的管理 用户账号的管理工作主要涉及到用户账号的添加、修改和删除。 添加用户账号就是在系统中创建一个新账号，然后为新账号分配用户号、用户组、主目录和登录Shell等资源。 添加账号 useradd useradd 选项 用户名 参数说明： 选项 : -c comment 指定一段注释性描述。 -d 目录 指定用户主目录，如果此目录不存在，则同时使用-m选项，可以创建主目录。 -g 用户组 指定用户所属的用户组。 -G 用户组，用户组 指定用户所属的附加组。 -m 使用者目录如不存在则自动建立。 -s Shell文件 指定用户的登录Shell。 -u 用户号 指定用户的用户号，如果同时有-o选项，则可以重复使用其他用户的标识号。 用户名 : 指定新账号的登录名。 测试： # 此命令创建了一个用户kuangshen，其中-m选项用来为登录名kuangshen产生一个主目录 /home/kuangshen[root@kuangshen home]# useradd -m kuangshen 增加用户账号就是在/etc/passwd文件中为新用户增加一条记录，同时更新其他系统文件如/etc/shadow, /etc/group等。 Linux下如何切换用户 1.切换用户的命令为：su username 【username是你的用户名哦】 2.从普通用户切换到root用户，还可以使用命令：sudo su 3.在终端输入exit或logout或使用快捷方式ctrl+d，可以退回到原来用户，其实ctrl+d也是执行的exit命令 4.在切换用户时，如果想在切换用户之后使用新用户的工作环境，可以在su和username之间加-，例如：【su - root】 $表示普通用户 #表示超级用户，也就是root用户 删除帐号 如果一个用户的账号不再使用，可以从系统中删除。 删除用户账号就是要将/etc/passwd等系统文件中的该用户记录删除，必要时还删除用户的主目录。 删除一个已有的用户账号使用userdel命令，其格式如下： userdel 选项 用户名 常用的选项是 -r，它的作用是把用户的主目录一起删除。 [root@kuangshen home]# userdel -r kuangshen 此命令删除用户kuangshen在系统文件中（主要是/etc/passwd, /etc/shadow, /etc/group等）的记录，同时删除用户的主目录。 修改帐号 修改用户账号就是根据实际情况更改用户的有关属性，如用户号、主目录、用户组、登录Shell等。 修改已有用户的信息使用usermod命令，其格式如下： usermod 选项 用户名 常用的选项包括-c, -d, -m, -g, -G, -s, -u以及-o等，这些选项的意义与useradd命令中的选项一样，可以为用户指定新的资源值。 例如： # usermod -s /bin/ksh -d /home/z –g developer kuangshen 此命令将用户kuangshen的登录Shell修改为ksh，主目录改为/home/z，用户组改为developer。 用户口令的管理 用户管理的一项重要内容是用户口令的管理。用户账号刚创建时没有口令，但是被系统锁定，无法使用，必须为其指定口令后才可以使用，即使是指定空口令。 指定和修改用户口令的Shell命令是passwd。超级用户可以为自己和其他用户指定口令，普通用户只能用它修改自己的口令。 命令的格式为： passwd 选项 用户名 可使用的选项： -l 锁定口令，即禁用账号。 -u 口令解锁。 -d 使账号无口令。 -f 强迫用户下次登录时修改口令。 如果默认用户名，则修改当前用户的口令。 例如，假设当前用户是kuangshen，则下面的命令修改该用户自己的口令： $ passwd Old password:******New password:*******Re-enter new password:******* 如果是超级用户，可以用下列形式指定任何用户的口令： # passwd kuangshenNew password:*******Re-enter new password:******* 普通用户修改自己的口令时，passwd命令会先询问原口令，验证后再要求用户输入两遍新口令，如果两次输入的口令一致，则将这个口令指定给用户；而超级用户为用户指定口令时，就不需要知道原口令。 为了系统安全起见，用户应该选择比较复杂的口令，例如最好使用8位长的口令，口令中包含有大写、小写字母和数字，并且应该与姓名、生日等不相同。 为用户指定空口令时，执行下列形式的命令： # passwd -d kuangshen 此命令将用户 kuangshen的口令删除，这样用户 kuangshen下一次登录时，系统就不再允许该用户登录了。 passwd 命令还可以用 -l(lock) 选项锁定某一用户，使其不能登录，例如： # passwd -l kuangshen 用户组管理每个用户都有一个用户组，系统可以对一个用户组中的所有用户进行集中管理。不同Linux 系统对用户组的规定有所不同，如Linux下的用户属于与它同名的用户组，这个用户组在创建用户时同时创建。 用户组的管理涉及用户组的添加、删除和修改。组的增加、删除和修改实际上就是对/etc/group文件的更新。 增加一个新的用户组使用groupadd命令 groupadd 选项 用户组 可以使用的选项有： -g GID 指定新用户组的组标识号（GID）。 -o 一般与-g选项同时使用，表示新用户组的GID可以与系统已有用户组的GID相同。 实例1： # groupadd group1 此命令向系统中增加了一个新组group1，新组的组标识号是在当前已有的最大组标识号的基础上加1。 实例2： # groupadd -g 101 group2 此命令向系统中增加了一个新组group2，同时指定新组的组标识号是101。 如果要删除一个已有的用户组，使用groupdel命令 groupdel 用户组 例如： # groupdel group1 此命令从系统中删除组group1。 修改用户组的属性使用groupmod命令 groupmod 选项 用户组 常用的选项有： -g GID 为用户组指定新的组标识号。 -o 与-g选项同时使用，用户组的新GID可以与系统已有用户组的GID相同。 -n新用户组 将用户组的名字改为新名字 # 此命令将组group2的组标识号修改为102。groupmod -g 102 group2# 将组group2的标识号改为10000，组名修改为group3。groupmod –g 10000 -n group3 group2 切换组 如果一个用户同时属于多个用户组，那么用户可以在用户组之间切换，以便具有其他用户组的权限。 用户可以在登录后，使用命令newgrp切换到其他用户组，这个命令的参数就是目的用户组。例如： $ newgrp root 这条命令将当前用户切换到root用户组，前提条件是root用户组确实是该用户的主组或附加组。 /etc/passwd 完成用户管理的工作有许多种方法，但是每一种方法实际上都是对有关的系统文件进行修改。 与用户和用户组相关的信息都存放在一些系统文件中，这些文件包括/etc/passwd, /etc/shadow, /etc/group等。 下面分别介绍这些文件的内容。 /etc/passwd文件是用户管理工作涉及的最重要的一个文件。 Linux系统中的每个用户都在/etc/passwd文件中有一个对应的记录行，它记录了这个用户的一些基本属性。 这个文件对所有用户都是可读的。它的内容类似下面的例子： ＃ cat /etc/passwdroot:x:0:0:Superuser:/:daemon:x:1:1:System daemons:/etc:bin:x:2:2:Owner of system commands:/bin:sys:x:3:3:Owner of system files:/usr/sys:adm:x:4:4:System accounting:/usr/adm:uucp:x:5:5:UUCP administrator:/usr/lib/uucp:auth:x:7:21:Authentication administrator:/tcb/files/auth:cron:x:9:16:Cron daemon:/usr/spool/cron:listen:x:37:4:Network daemon:/usr/net/nls:lp:x:71:18:Printer administrator:/usr/spool/lp: 从上面的例子我们可以看到，/etc/passwd中一行记录对应着一个用户，每行记录又被冒号(:)分隔为7个字段，其格式和具体含义如下： 用户名:口令:用户标识号:组标识号:注释性描述:主目录:登录Shell 1）”用户名”是代表用户账号的字符串。 通常长度不超过8个字符，并且由大小写字母和/或数字组成。登录名中不能有冒号(:)，因为冒号在这里是分隔符。 为了兼容起见，登录名中最好不要包含点字符(.)，并且不使用连字符(-)和加号(+)打头。 2）“口令”一些系统中，存放着加密后的用户口令字。 虽然这个字段存放的只是用户口令的加密串，不是明文，但是由于/etc/passwd文件对所有用户都可读，所以这仍是一个安全隐患。因此，现在许多Linux 系统（如SVR4）都使用了shadow技术，把真正的加密后的用户口令字存放到/etc/shadow文件中，而在/etc/passwd文件的口令字段中只存放一个特殊的字符，例如“x”或者“*”。 3）“用户标识号”是一个整数，系统内部用它来标识用户。 一般情况下它与用户名是一一对应的。如果几个用户名对应的用户标识号是一样的，系统内部将把它们视为同一个用户，但是它们可以有不同的口令、不同的主目录以及不同的登录Shell等。 通常用户标识号的取值范围是0～65 535。0是超级用户root的标识号，1～99由系统保留，作为管理账号，普通用户的标识号从100开始。在Linux系统中，这个界限是500。 4）“组标识号”字段记录的是用户所属的用户组。 它对应着/etc/group文件中的一条记录。 5)“注释性描述”字段记录着用户的一些个人情况。 例如用户的真实姓名、电话、地址等，这个字段并没有什么实际的用途。在不同的Linux 系统中，这个字段的格式并没有统一。在许多Linux系统中，这个字段存放的是一段任意的注释性描述文字，用作finger命令的输出。 6)“主目录”，也就是用户的起始工作目录。 它是用户在登录到系统之后所处的目录。在大多数系统中，各用户的主目录都被组织在同一个特定的目录下，而用户主目录的名称就是该用户的登录名。各用户对自己的主目录有读、写、执行（搜索）权限，其他用户对此目录的访问权限则根据具体情况设置。 7)用户登录后，要启动一个进程，负责将用户的操作传给内核，这个进程是用户登录到系统后运行的命令解释器或某个特定的程序，即Shell。 Shell是用户与Linux系统之间的接口。Linux的Shell有许多种，每种都有不同的特点。常用的有sh(Bourne Shell), csh(C Shell), ksh(Korn Shell), tcsh(TENEX/TOPS-20 type C Shell), bash(Bourne Again Shell)等。 系统管理员可以根据系统情况和用户习惯为用户指定某个Shell。如果不指定Shell，那么系统使用sh为默认的登录Shell，即这个字段的值为/bin/sh。 用户的登录Shell也可以指定为某个特定的程序（此程序不是一个命令解释器）。 利用这一特点，我们可以限制用户只能运行指定的应用程序，在该应用程序运行结束后，用户就自动退出了系统。有些Linux 系统要求只有那些在系统中登记了的程序才能出现在这个字段中。 8)系统中有一类用户称为伪用户（pseudo users）。 这些用户在/etc/passwd文件中也占有一条记录，但是不能登录，因为它们的登录Shell为空。它们的存在主要是方便系统管理，满足相应的系统进程对文件属主的要求。 常见的伪用户如下所示： 伪 用 户 含 义bin 拥有可执行的用户命令文件sys 拥有系统文件adm 拥有帐户文件uucp UUCP使用lp lp或lpd子系统使用nobody NFS使用 /etc/shadow 1、除了上面列出的伪用户外，还有许多标准的伪用户，例如：audit, cron, mail, usenet等，它们也都各自为相关的进程和文件所需要。 由于/etc/passwd文件是所有用户都可读的，如果用户的密码太简单或规律比较明显的话，一台普通的计算机就能够很容易地将它破解，因此对安全性要求较高的Linux系统都把加密后的口令字分离出来，单独存放在一个文件中，这个文件是/etc/shadow文件。有超级用户才拥有该文件读权限，这就保证了用户密码的安全性。 2、/etc/shadow中的记录行与/etc/passwd中的一一对应，它由pwconv命令根据/etc/passwd中的数据自动产生 它的文件格式与/etc/passwd类似，由若干个字段组成，字段之间用”:”隔开。这些字段是： 登录名:加密口令:最后一次修改时间:最小时间间隔:最大时间间隔:警告时间:不活动时间:失效时间:标志 “登录名”是与/etc/passwd文件中的登录名相一致的用户账号 “口令”字段存放的是加密后的用户口令字，长度为13个字符。如果为空，则对应用户没有口令，登录时不需要口令；如果含有不属于集合 { ./0-9A-Za-z }中的字符，则对应的用户不能登录。 “最后一次修改时间”表示的是从某个时刻起，到用户最后一次修改口令时的天数。时间起点对不同的系统可能不一样。例如在SCO Linux 中，这个时间起点是1970年1月1日。 “最小时间间隔”指的是两次修改口令之间所需的最小天数。 “最大时间间隔”指的是口令保持有效的最大天数。 “警告时间”字段表示的是从系统开始警告用户到用户密码正式失效之间的天数。 “不活动时间”表示的是用户没有登录活动但账号仍能保持有效的最大天数。 “失效时间”字段给出的是一个绝对的天数，如果使用了这个字段，那么就给出相应账号的生存期。期满后，该账号就不再是一个合法的账号，也就不能再用来登录了。 /etc/group 用户组的所有信息都存放在/etc/group文件中。 将用户分组是Linux 系统中对用户进行管理及控制访问权限的一种手段。 每个用户都属于某个用户组；一个组中可以有多个用户，一个用户也可以属于不同的组。 当一个用户同时是多个组中的成员时，在/etc/passwd文件中记录的是用户所属的主组，也就是登录时所属的默认组，而其他组称为附加组。 用户要访问属于附加组的文件时，必须首先使用newgrp命令使自己成为所要访问的组中的成员。 用户组的所有信息都存放在/etc/group文件中。此文件的格式也类似于/etc/passwd文件，由冒号(:)隔开若干个字段，这些字段有： 组名:口令:组标识号:组内用户列表 “组名”是用户组的名称，由字母或数字构成。与/etc/passwd中的登录名一样，组名不应重复。 “口令”字段存放的是用户组加密后的口令字。一般Linux 系统的用户组都没有口令，即这个字段一般为空，或者是*。 “组标识号”与用户标识号类似，也是一个整数，被系统内部用来标识组。 “组内用户列表”是属于这个组的所有用户的列表/b]，不同用户之间用逗号(,)分隔。这个用户组可能是用户的主组，也可能是附加组。 磁盘管理 概述 Linux磁盘管理好坏直接关系到整个系统的性能问题。 Linux磁盘管理常用命令为 df、du。 df ：列出文件系统的整体磁盘使用量 du：检查磁盘空间使用量 df df命令参数功能：检查文件系统的磁盘空间占用情况。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 语法： df [-ahikHTm] [目录或文件名] 选项与参数： -a ：列出所有的文件系统，包括系统特有的 /proc 等文件系统； -k ：以 KBytes 的容量显示各文件系统； -m ：以 MBytes 的容量显示各文件系统； -h ：以人们较易阅读的 GBytes, MBytes, KBytes 等格式自行显示； -H ：以 M=1000K 取代 M=1024K 的进位方式； -T ：显示文件系统类型, 连同该 partition 的 filesystem 名称 (例如 ext3) 也列出； -i ：不用硬盘容量，而以 inode 的数量来显示 测试： # 将系统内所有的文件系统列出来！# 在 Linux 底下如果 df 没有加任何选项# 那么默认会将系统内所有的 (不含特殊内存内的文件系统与 swap) 都以 1 Kbytes 的容量来列出来！[root@kuangshen /]# dfFilesystem 1K-blocks Used Available Use% Mounted ondevtmpfs 889100 0 889100 0% /devtmpfs 899460 704 898756 1% /dev/shmtmpfs 899460 496 898964 1% /runtmpfs 899460 0 899460 0% /sys/fs/cgroup/dev/vda1 41152812 6586736 32662368 17% /tmpfs 179896 0 179896 0% /run/user/0# 将容量结果以易读的容量格式显示出来[root@kuangshen /]# df -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 869M 0 869M 0% /devtmpfs 879M 708K 878M 1% /dev/shmtmpfs 879M 496K 878M 1% /runtmpfs 879M 0 879M 0% /sys/fs/cgroup/dev/vda1 40G 6.3G 32G 17% /tmpfs 176M 0 176M 0% /run/user/0# 将系统内的所有特殊文件格式及名称都列出来[root@kuangshen /]# df -aTFilesystem Type 1K-blocks Used Available Use% Mounted onsysfs sysfs 0 0 0 - /sysproc proc 0 0 0 - /procdevtmpfs devtmpfs 889100 0 889100 0% /devsecurityfs securityfs 0 0 0 - /sys/kernel/securitytmpfs tmpfs 899460 708 898752 1% /dev/shmdevpts devpts 0 0 0 - /dev/ptstmpfs tmpfs 899460 496 898964 1% /runtmpfs tmpfs 899460 0 899460 0% /sys/fs/cgroupcgroup cgroup 0 0 0 - /sys/fs/cgroup/systemdpstore pstore 0 0 0 - /sys/fs/pstorecgroup cgroup 0 0 0 - /sys/fs/cgroup/freezercgroup cgroup 0 0 0 - /sys/fs/cgroup/cpusetcgroup cgroup 0 0 0 - /sys/fs/cgroup/hugetlbcgroup cgroup 0 0 0 - /sys/fs/cgroup/blkiocgroup cgroup 0 0 0 - /sys/fs/cgroup/net_cls,net_priocgroup cgroup 0 0 0 - /sys/fs/cgroup/memorycgroup cgroup 0 0 0 - /sys/fs/cgroup/pidscgroup cgroup 0 0 0 - /sys/fs/cgroup/cpu,cpuacctcgroup cgroup 0 0 0 - /sys/fs/cgroup/devicescgroup cgroup 0 0 0 - /sys/fs/cgroup/perf_eventconfigfs configfs 0 0 0 - /sys/kernel/config/dev/vda1 ext4 41152812 6586748 32662356 17% /systemd-1 - - - - - /proc/sys/fs/binfmt_miscmqueue mqueue 0 0 0 - /dev/mqueuedebugfs debugfs 0 0 0 - /sys/kernel/debughugetlbfs hugetlbfs 0 0 0 - /dev/hugepagestmpfs tmpfs 179896 0 179896 0% /run/user/0binfmt_misc binfmt_misc 0 0 0 - /proc/sys/fs/binfmt_misc# 将 /etc 底下的可用的磁盘容量以易读的容量格式显示[root@kuangshen /]# df -h /etcFilesystem Size Used Avail Use% Mounted on/dev/vda1 40G 6.3G 32G 17% / du Linux du命令也是查看使用空间的，但是与df命令不同的是Linux du命令是对文件和目录磁盘使用的空间的查看，还是和df命令有一些区别的，这里介绍Linux du命令。 语法： du [-ahskm] 文件或目录名称 选项与参数： -a ：列出所有的文件与目录容量，因为默认仅统计目录底下的文件量而已。 -h ：以人们较易读的容量格式 (G/M) 显示； -s ：列出总量而已，而不列出每个各别的目录占用容量； -S ：不包括子目录下的总计，与 -s 有点差别。 -k ：以 KBytes 列出容量显示； -m ：以 MBytes 列出容量显示； 测试： # 只列出当前目录下的所有文件夹容量（包括隐藏文件夹）:# 直接输入 du 没有加任何选项时，则 du 会分析当前所在目录的文件与目录所占用的硬盘空间。[root@kuangshen home]# du16./redis8./www/.oracle_jre_usage # 包括隐藏文件的目录24./www48. # 这个目录(.)所占用的总量# 将文件的容量也列出来[root@kuangshen home]# du -a4./redis/.bash_profile4./redis/.bash_logout ....中间省略....4./kuangstudy.txt # 有文件的列表了48.# 检查根目录底下每个目录所占用的容量[root@kuangshen home]# du -sm /*0/bin146/boot.....中间省略....0/proc.....中间省略....1/tmp3026/usr # 系统初期最大就是他了啦！513/var2666/www 通配符 * 来代表每个目录。 与 df 不一样的是，du 这个命令其实会直接到文件系统内去搜寻所有的文件数据。 磁盘挂载与卸除 根文件系统之外的其他文件要想能够被访问，都必须通过“关联”至根文件系统上的某个目录来实现，此关联操作即为“挂载”，此目录即为“挂载点”,解除此关联关系的过程称之为“卸载” Linux 的磁盘挂载使用mount命令，卸载使用umount命令。 磁盘挂载语法： mount [-t 文件系统] [-L Label名] [-o 额外选项] [-n] 装置文件名 挂载点 测试： # 将 /dev/hdc6 挂载到 /mnt/hdc6 上面！[root@www ~]# mkdir /mnt/hdc6[root@www ~]# mount /dev/hdc6 /mnt/hdc6[root@www ~]# dfFilesystem 1K-blocks Used Available Use% Mounted on/dev/hdc6 1976312 42072 1833836 3% /mnt/hdc6 磁盘卸载命令 umount 语法： umount [-fn] 装置文件名或挂载点 选项与参数： -f ：强制卸除！可用在类似网络文件系统 (NFS) 无法读取到的情况下； -n ：不升级 /etc/mtab 情况下卸除。 卸载/dev/hdc6 [root@www ~]# umount /dev/hdc6 #Linux04-三种软件安装方式及服务器基本环境搭建 ##一. JDK安装（rpm安装） 1、rpm下载地址http://www.oracle.com/technetwork/java/javase/downloads/index.html 2、如果有安装openjdk 则卸载 [root@kuangshen ~]# java -versionjava version \"1.8.0_121\"Java(TM) SE Runtime Environment (build 1.8.0_121-b13)Java HotSpot(TM) 64-Bit Server VM (build 25.121-b13, mixed mode)# 检查[root@kuangshen ~]# rpm -qa|grep jdkjdk1.8.0_121-1.8.0_121-fcs.x86_64# 卸载 -e --nodeps 强制删除[root@kuangshen ~]# rpm -e --nodeps jdk1.8.0_121-1.8.0_121-fcs.x86_64[root@kuangshen ~]# java -version-bash: /usr/bin/java: No such file or directory # OK 3、安装JDK # 安装java rpm[root@kuangshen kuangshen]# rpm -ivh jdk-8u221-linux-x64.rpm# 安装完成后配置环境变量 文件：/etc/profileJAVA_HOME=/usr/java/jdk1.8.0_221-amd64CLASSPATH=%JAVA_HOME%/lib:%JAVA_HOME%/jre/libPATH=$PATH:$JAVA_HOME/bin:$JAVA_HOME/jre/binexport PATH CLASSPATH JAVA_HOME# 保存退出# 让新增的环境变量生效！source /etc/profile# 测试 java -version[root@kuangshen java]# java -versionjava version \"1.8.0_221\"Java(TM) SE Runtime Environment (build 1.8.0_221-b11)Java HotSpot(TM) 64-Bit Server VM (build 25.221-b11, mixed mode) ##二. Tomcat安装（解压缩安装） 1、安装好了Java环境后我们可以测试下Tomcat！准备好Tomcat的安装包！ 2、将文件移动到/usr/tomcat/下，并解压！ [root@kuangshen kuangshen]# mv apache-tomcat-9.0.22.tar.gz /usr[root@kuangshen kuangshen]# cd /usr[root@kuangshen usr]# lsapache-tomcat-9.0.22.tar.gz[root@kuangshen usr]# tar -zxvf apache-tomcat-9.0.22.tar.gz # 解压 3、运行Tomcat，进入bin目录，和我们以前在Windows下看的都是一样的 # 执行：startup.sh -->启动tomcat# 执行：shutdown.sh -->关闭tomcat./startup.sh./shutdown.sh 4、确保Linux的防火墙端口是开启的，如果是阿里云，需要保证阿里云的安全组策略是开放的！ # 查看firewall服务状态systemctl status firewalld# 开启、重启、关闭、firewalld.service服务# 开启service firewalld start# 重启service firewalld restart# 关闭service firewalld stop# 查看防火墙规则firewall-cmd --list-all # 查看全部信息firewall-cmd --list-ports # 只看端口信息# 开启端口开端口命令：firewall-cmd --zone=public --add-port=80/tcp --permanent重启防火墙：systemctl restart firewalld.service命令含义：--zone #作用域--add-port=80/tcp #添加端口，格式为：端口/通讯协议--permanent #永久生效，没有此参数重启后失效 ##三. 安装Docker（yum安装） 基于 CentOS 7 安装 官网安装参考手册：https://docs.docker.com/install/linux/docker-ce/centos/ 确定你是CentOS7及以上版本 [root@192 Desktop]# cat /etc/redhat-releaseCentOS Linux release 7.2.1511 (Core) yum安装gcc相关（需要确保 虚拟机可以上外网 ） yum -y install gccyum -y install gcc-c++ 卸载旧版本 yum -y remove docker docker-common docker-selinux docker-engine# 官网版本yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 安装需要的软件包 yum install -y yum-utils device-mapper-persistent-data lvm2 设置stable镜像仓库 # 错误yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo## 报错[Errno 14] curl#35 - TCP connection reset by peer[Errno 12] curl#35 - Timeout# 正确推荐使用国内的yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 更新yum软件包索引 yum makecache fast 安装Docker CE yum -y install docker-ce docker-ce-cli containerd.io 启动docker systemctl start docker 测试 docker versiondocker run hello-worlddocker images 四. 宝塔面板安装https://www.bilibili.com/video/av91821322 说明：后面我们会在Linux搭建很多环境，每个环境的搭建留在每个对应的课程中去讲解、比如Redis、Kafka、Elasticsearch等等….. 这里大家只需要掌握基本的套路即可！","permalink":"https://shitianshuai1111.github.io/2017/06/29/Linux%E7%B3%BB%E7%BB%9F/","photos":[]},{"tags":[{"name":"笔记","slug":"笔记","permalink":"https://shitianshuai1111.github.io/tags/%E7%AC%94%E8%AE%B0/"}],"title":"Rap2平台 Docker方式搭建","date":"2017/06/25","text":"Rap2平台 Docker方式搭建一. 自动部署1. 安装 Docker国内用户可参考 https://get.daocloud.io/ 安装 Docker 以及 Docker Compose (Linux 用户需要单独安装)，建议按照链接指引配置 Docker Hub 的国内镜像提高加载速度。 2. 配置项目在任意地方建立目录 rap 把本仓库中的 docker-compose.yml 放到 rap 目录中 # 2020.7.3日版# mail@dongguochao.com# llitfkitfk@gmail.com# chibing.fy@alibaba-inc.comversion: \"3\"services: # frontend dolores: image: rapteam/rap2-dolores:latest ports: #冒号前可以自定义前端端口号，冒号后不要动 - 3000:38081 # backend delos: image: rapteam/rap2-delos:latest ports: # 这里的配置不要改哦 - 38080:38080 environment: - SERVE_PORT=38080 # if you have your own mysql, config it here, and disable the 'mysql' config blow - MYSQL_URL=mysql # links will maintain /etc/hosts, just use 'container_name' - MYSQL_PORT=3306 - MYSQL_USERNAME=root - MYSQL_PASSWD= - MYSQL_SCHEMA=rap2 # redis config - REDIS_URL=redis - REDIS_PORT=6379 # production / development - NODE_ENV=production # email 如果想让邮箱找回密码能力生效需要配置邮件发送 - MAIL_HOST=smtp.aliyun.com - MAIL_PORT=465 - MAIL_USER=rap2org@service.alibaba.com - MAIL_PASS=xxxxxx - MAIL_SENDER=rap2org@service.alibaba.com ###### 'sleep 30 && node scripts/init' will drop the tables ###### RUN ONLY ONCE THEN REMOVE 'sleep 30 && node scripts/init' command: /bin/sh -c 'node dispatch.js' # init the databases # command: sleep 30 && node scripts/init && node dispatch.js # without init # command: node dispatch.js depends_on: - redis - mysql redis: image: redis:4 # disable this if you have your own mysql mysql: image: mysql:5.7 # expose 33306 to client (navicat) #ports: # - 33306:3306 volumes: # change './docker/mysql/volume' to your own path # WARNING: without this line, your data will be lost. - \"./docker/mysql/volume:/var/lib/mysql\" command: mysqld --character-set-server=utf8mb4 --collation-server=utf8mb4_unicode_ci --init-connect='SET NAMES utf8mb4;' --innodb-flush-log-at-trx-commit=0 environment: MYSQL_ALLOW_EMPTY_PASSWORD: \"true\" MYSQL_DATABASE: \"rap2\" MYSQL_USER: \"root\" MYSQL_PASSWORD: \"\" Rap 前端服务的端口号默认为 3000，你可以在 docker-compose.yml 中按照注释自定义 3. 执行命令在 rap 目录下执行下面的命令： # 拉取镜像并启动docker-compose up -d# 启动后，第一次运行需要手动初始化mysql数据库# ⚠️注意: 只有第一次该这样做docker-compose exec delos node scripts/init# 部署成功后 访问http://localhost:3000 # 前端（可自定义端口号）http://localhost:38080 # 后端# 如果访问不了可能是数据库没有链接上，关闭 rap 服务docker-compose down# 再重新运行docker-compose up -d# 如果 Sequelize 报错可能是数据库表发生了变化，运行下面命令同步docker-compose exec delos node scripts/updateSchema ⚠️注意：第一次运行后 rap 目录下会被自动创建一个 docker 目录，里面存有 rap 的数据库数据，可千万不要删除。 4. 镜像升级Rap 经常会进行 bugfix 和功能升级，用 Docker 可以很方便地跟随主项目升级 # 拉取一下最新的镜像docker-compose pull# 暂停当前应用docker-compose down# 重新构建并启动docker-compose up -d --build# 有时表结构会发生变化，执行下面命令同步docker-compose exec delos node scripts/updateSchema# 清空不被使用的虚悬镜像docker image prune -f 二. 手动部署1. 环境要求 Node.js 8.9.4+ MySQL 5.7+ Redis 4.0+ pandoc 2.73 (供文档生成使用) 2. 开发模式2.1 安装 MySQL 和 Redis 服务器请自行查找搭建方法，mysql/redis 配置在 config.*.ts 文件中，在不修改任何配置的情况下， redis 会通过默认端口 + 本机即可正常访问，确保 redis-server 打开即可。 注意：修改 cofig 文件后需要重新 npm run build 才能生效 2.2 安装 pandoc我们使用 pandoc 来生成 Rap 的离线文档，安装 Pandoc 最通用的办法是在 pandoc 的 release 页面下载对应平台的二进制文件安装即可。 其中 linux 版本最好放在/usr/local/bin/pandoc 让终端能直接找到，并执行 chmod +x /usr/local/bin/pandoc 给调用权限。 测试在命令行执行命令 pandoc -h 有响应即可。 启动redis-serverredis-server 后台执行可以使用 nohup 或 pm2，这里推荐使用 pm2，下面命令会安装 pm2，并通过 pm2 来启动 redis 缓存服务 npm install -g pm2npm run start:redis 2.4 先创建创建数据库mysql -e 'CREATE DATABASE IF NOT EXISTS RAP2_DELOS_APP DEFAULT CHARSET utf8 COLLATE utf8_general_ci' 2.5 初始化npm install confirm configurations in /config/config.dev.js (used in development mode)，确认/config/config.dev.js 中的配置(.dev.js 后缀表示用于开发模式)。 2.6 安装 && TypeScript 编译npm install -g typescriptnpm run build 2.7初始化数据库表npm run create-db 2.8执行 mocha 测试用例和 js 代码规范检查npm run check 2.9 启动开发模式的服务器 监视并在发生代码变更时自动重启npm run dev 3. 生产模式# 1. 修改/config/config.prod.js中的服务器配置# 2. 启动生产模式服务器npm start Tech Arch 前端架构(rap2-dolores) React / Redux / Saga / Router Mock.js SASS / Bootstrap 4 beta server: nginx 后端架构(rap2-delos) Koa Sequelize MySQL Server server: node","permalink":"https://shitianshuai1111.github.io/2017/06/25/Rap2%E5%B9%B3%E5%8F%B0-Docker%E6%96%B9%E5%BC%8F%E6%90%AD%E5%BB%BA/","photos":[]},{"tags":[{"name":"笔记","slug":"笔记","permalink":"https://shitianshuai1111.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"业务","slug":"业务","permalink":"https://shitianshuai1111.github.io/tags/%E4%B8%9A%E5%8A%A1/"}],"title":"Elasticsearch实现搜索","date":"2017/05/22","text":"Elasticsearch一. 是什么后台启动es su elsearchcd /opt/elastic.../bin./elasticsearch -d ik分词器 一. 使用场景一. 项目中使用mall项目的搜索模块: 目录结构 mall-search ​ |- src ​ |- main ​ |- java ​ |- com.mall.search ​ |- config ​ - MyBatisConfig ​ - Swagger2Config ​ |- controller ​ - EsProductController ​ |- dao ​ - EsProductDao ​ |- domain ​ - EsProduct ​ - EsProductAttributeValue ​ - EsProductRelatedInfo ​ |- repository ​ - EsProductRepository ​ |- service ​ |- impl ​ - EsProductServiceImpl ​ - EsProductService ​ - MallSearchApplication ​ |- resources ​ |- dao ​ |- EsProductDao.xml ​ - application.yml ​ - application-dev.yml ​ - application-prod.yml ​ - pom.xml 1.1 pom依赖 com.macro.mall mall-mbg org.springframework.boot spring-boot-starter-data-elasticsearch 1.2 controller接口/esProduct /importAll 导入所有数据库中商品到ES /delete/{id} 根据id删除商品 /delete/batch 根据id批量删除商品 /create/{id} 根据id创建商品 /search/simple 简单搜索 /search 综合搜索、筛选、排序 /recommend/{id} 根据商品id推荐商品 /search/relate 获取搜索的相关品牌、分类及筛选属性 二. 导入ES2.1 接口@ApiOperation(value = \"导入所有数据库中商品到ES\")@RequestMapping(value = \"/importAll\", method = RequestMethod.POST)@ResponseBodypublic CommonResult importAllList() { int count = esProductService.importAll(); return CommonResult.success(count);} importAll方法: @Overridepublic int importAll() { List esProductList = productDao.getAllEsProductList(null); Iterable esProductIterable = productRepository.saveAll(esProductList); Iterator iterator = esProductIterable.iterator(); int result = 0; while (iterator.hasNext()) { result++; iterator.next(); } return result;} select p.id id, p.product_sn productSn, p.brand_id brandId, p.brand_name brandName, p.product_category_id productCategoryId, p.product_category_name productCategoryName, p.pic pic, p.name name, p.sub_title subTitle, p.price price, p.sale sale, p.new_status newStatus, p.recommand_status recommandStatus, p.stock stock, p.promotion_type promotionType, p.keywords keywords, p.sort sort, pav.id attr_id, pav.value attr_value, pav.product_attribute_id attr_product_attribute_id, pa.type attr_type, pa.name attr_name from pms_product p left join pms_product_attribute_value pav on p.id = pav.product_id left join pms_product_attribute pa on pav.product_attribute_id= pa.id where delete_status = 0 and publish_status = 1 and p.id=#{id} 配置文件# ======================== Elasticsearch Configuration =========================## NOTE: Elasticsearch comes with reasonable defaults for most settings.# Before you set out to tweak and tune the configuration, make sure you# understand what are you trying to accomplish and the consequences.## es为大多数设置都给出了不错的默认值, 在你进行配置时, 确保你真的明白你这么做的影响以及结果.## The primary way of configuring a node is via this file. This template lists# the most important settings you may want to configure for a production cluster.# Please consult the documentation for further information on configuration options:# https://www.elastic.co/guide/en/elasticsearch/reference/index.html## 配置一个节点的主要方法之一就是通过这个文件, 这个模板罗列出了你可能想要配置集群的# 最重要的设置项.## ---------------------------------- Cluster -----------------------------------## Use a descriptive name for your cluster: 给你的集群设置一个集群名, 默认是elasticsearch# #cluster.name: my-application## ------------------------------------ Node ------------------------------------## Use a descriptive name for the node: 给你的节点设置节点名## 默认从elasticsearch-6.8.8.jar/lib/elasticsearch-6.8.8.jar!config/names.txt中随机选择一个名称##node.name: node-1## Add custom attributes to the node: 给你的节点设置一个标志(描述)##node.attr.rack: r1## ----------------------------------- Paths ------------------------------------## Path to directory where to store the data (separate multiple locations by comma):## 设置存储数据的目录的路径, 用逗号分隔多个位置, 默认存储在 es文件夹/data 目录下##path.data: /path/to/data## Path to log files: 默认在es文件夹/logs## 日志文件的路径##path.logs: /path/to/logs## ----------------------------------- Memory -----------------------------------## Lock the memory on startup: 锁定物理内存地址，防止elasticsearch内存被交换出去,# 也就是避免es使用swap交换分区##bootstrap.memory_lock: true## Make sure that the heap size is set to about half the memory available# on the system and that the owner of the process is allowed to use this# limit.## 确保将堆大小设置为可用内存的一半左右# 在系统上，并且允许进程的所有者使用此# 限制。## Elasticsearch performs poorly when the system is swapping the memory.# 当系统交换内存时，Elasticsearch的性能很差。# ---------------------------------- Network -----------------------------------## Set the bind address to a specific IP (IPv4 or IPv6):## 为es设置ip绑定，默认是127.0.0.1，也就是默认只能通过127.0.0.1 或者localhost才能访问## es1.x版本默认绑定的是0.0.0.0 所以不需要配置，但是es2.x版本默认绑定的是127.0.0.1，需要配置## network.host: 192.168.0.1## 生产环境, 这里换成0.0.0.0, 允许外部访问network.host: 0.0.0.0### Set a custom port for HTTP: 为es设置自定义端口，默认是9200## 注意：在同一个服务器中启动多个es节点的话，默认监听的端口号会自动加1：例如：9200，9201，9202...# http.port: 9200## For more information, consult the network module documentation. 更多的信息在网络文档上## --------------------------------- Discovery ----------------------------------# 当启动新节点时，通过这个ip列表进行节点发现，组建集群# 默认节点列表：# 127.0.0.1，表示ipv4的回环地址。# [::1]，表示ipv6的回环地址## 在es1.x中默认使用的是组播(multicast)协议，默认会自动发现同一网段的es节点组建集群，# 在es2.x中默认使用的是单播(unicast)协议，想要组建集群的话就需要在这指定要发现的节点信息了。# 注意：如果是发现其他服务器中的es服务，可以不指定端口[默认9300]，如果是发现同一个服务器中的es服务，就需要指定端口了。## Pass an initial list of hosts to perform discovery when new node is started:# The default list of hosts is [\"127.0.0.1\", \"[::1]\"]##discovery.zen.ping.unicast.hosts: [\"host1\", \"host2\"]## Prevent the \"split brain\" by configuring the majority of nodes (total number of master-eligible nodes / 2 + 1):# 通过配置这个参数来防止集群脑裂现象 (集群总节点数量/2)+1##discovery.zen.minimum_master_nodes: (集群总节点数量/2)+1## For more information, consult the zen discovery module documentation.## ---------------------------------- Gateway -----------------------------------## Block initial recovery after a full cluster restart until N nodes are started:# 一个集群中的N个节点启动后,才允许进行数据恢复处理，默认是1##gateway.recover_after_nodes: 3## For more information, consult the gateway module documentation.## ---------------------------------- Various -----------------------------------# 多样化配置:## Require explicit names when deleting indices: 删除节点时需要明确的支出##action.destructive_requires_name: true###总结## 1、es已经为大多数参数设置合理的默认值## 2、这个配置文件中列出来了针对生产环境下的一些重要配置## 3、注意：这个文件是yaml格式的文件## （1）：属性顶格写，不能有空格## （2）：缩进一定不能使用tab制表符## （3）：属性和值之间的:后面需要有空格# network.host: 192.168.80.200# 坑1. 在centos7上以root用户启动elasticsearch时, 提示不能以root形式启动 原因: 出于系统安全考虑的设置 ，不允许root账号启动 [root@iz2zect9h9unbhaoadluycz bin]# sudo ./elasticsearch[2020-04-23T14:51:31,719][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [unknown] uncaught exception in thread [main]org.elasticsearch.bootstrap.StartupException: java.lang.RuntimeException: can not run elasticsearch as rootCaused by: java.lang.RuntimeException: can not run elasticsearch as root 解决方法: 创建elsearch用户组及elsearch用户：groupadd elsearchuseradd elsearch -g elsearchpasswd elsearch更改elasticsearch文件夹及内部文件的所属用户及组为elsearch:elsearchcd /optchown -R elsearch:elsearch elasticsearch-6.8.8切换到elsearch用户再启动su elsearch cd /opt/elasticsearch-6.8.8/bin./elasticsearch 2. 本地项目连接远程es时服务可用, 但报错Connection refused的问题Es远程连接elasticsearch时, 会在本地localhost:9200进行一次Elasticsearch health check, 而本地此时是没有启动es的, 此时就会报错java.net.ConnectException: Connection refused 这种检测意义不大, 可以关闭, 或者设置为远程线上检查 management: health: elasticsearch: enabled: false 3. elasticsearch使用两个端口restful接口9200和tcp接口9300, 在云服务器的安全组配置中, 要开放这两个端口, 如果使用了宝塔面板, 在宝塔中也要配置开放端口. 项目中使用的是9300接口 spring: data: elasticsearch: repositories: enabled: true cluster-nodes: xxx.xxx.xx.xx:9300 https://blog.csdn.net/lixiaohai_918/article/details/89569611","permalink":"https://shitianshuai1111.github.io/2017/05/22/Elasticsearch/","photos":[]},{"tags":[{"name":"干货","slug":"干货","permalink":"https://shitianshuai1111.github.io/tags/%E5%B9%B2%E8%B4%A7/"},{"name":"笔记","slug":"笔记","permalink":"https://shitianshuai1111.github.io/tags/%E7%AC%94%E8%AE%B0/"}],"title":"MongoDB用法","date":"2017/04/25","text":"MongoDB用法##1. mongoDB存储数据 创建集合Collection -> 对应传统数据库的表table 命令: db.createCollection(name, options) eg:db.createCollection(\"mycol\", {capped: true, autoIndexId: true, size: 6142800, max: 10000 })1. name是集合的名字2. options为集合的可选参数 ● capped 布尔(如果为 true，则创建固定集合。固定集合是指有着固定大小的集合，当达到最大值时，它会自动覆盖最早的文档。当该值为 true 时，必须指定 size 参数。 ●autoIndexId 布尔 如为 true，自动在_id字段创建索引。默认为false。 ●size 数值 为固定集合指定一个最大值，以千字节计（KB）。如果 capped 为 true，也需要指定该字段。 ●max 数值 指定固定集合中包含文档的最大数量。 插入文档 命令: db.COLLECTION_NAME.insert(document)eg:db.col.insert({ \"_id\": ObjectId(\"5dfb71b9f6f3fb2a9e1bfb46\"), \"ASPD_ID\": \"10288094\", \"ASPD_Nm\": \"缘定三生炽热红25g（电子渠道）\", ... \"Br_Sell_Prc\": \"598\", \"Can_Bybk_Ind\": \"0\", \"Co_Nm\": \"紫金矿业集团黄金珠宝有限公司\", \"Wght_UnCd\": \"0702\"}) 插入文档你也可以使用 db.COLLECTION_NAME.save(document) 命令。如果不指定 _id 字段 save() 方法类似于 insert() 方法。如果指定 _id 字段，则会更新该 _id 的数据。即通过传入的文档来替换已有文档. 以及: db.COLLECTION_NAME.insertOne():向指定集合中插入一条文档数据 db.COLLECTION_NAME.insertMany():向指定集合中插入多条文档数据 更新文档 db.COLLECTION_NAME.update( , , { upsert: , multi: , writeConcern: })eg:db.COLLECTION_NAME.update({'ASPD_Nm':'缘定三生炽热红25g（电子渠道）'}, {$set:{'ASPD_Nm':'缘定三生炽热红25g（线下渠道）'})- 以上命令就可以实现: 把ASPD_Nm为缘定三生炽热红25g（电子渠道）的数据中的ASPD_Nm字段的内容, 修改为ASPD_Nm':'缘定三生炽热红25g（线下渠道）1. 参数说明query : update的查询条件，类似sql update查询内where后面的。update : update的对象和一些更新的操作符（如$,$inc...）等，也可以理解为sql update查询内set后面的upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入。multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。writeConcern :可选，抛出异常的级别。 删除文档 db.COLLECTION_NAME.remove( , { justOne: , writeConcern: })eg: db.COLLECTION_NAME.remove({'ASPD_Nm':'缘定三生炽热红25g（电子渠道）'})参数说明:query:(可选)删除的文档的条件。justOne:(可选)如果设为 true或1，则只删除一个文档如果不设置该参数或使用默认值 false则删除所有匹配条件的文档。writeConcern:(可选)抛出异常的级别。 如果想删除所有数据可以使用: db.col.remove({}) 类似于数据库的truncate 查询文档 db.COLLECTION_NAME.find(query, projection)eg:db.apsd_data.find({\"ASPD_Nm\":\"缘定三生炽热红25g（电子渠道）\", \"Co_Nm\":\"紫金矿业集团黄金珠宝有限公司\"}).pretty()参数说明: query: 可选,使用查询操作符指定查询条件projection: 可选,使用投影操作符指定返回的键。查询时返回文档中所有键值, 只需省略该参数即可（默认省略）。● 可以在查询后追加.pretty()方法使得结果更易读 查询常见的有and与or两种关系. and查询可以直接在查询语句中 “ , “分隔, 而or则需要使用$or: db.COLLECTION_NAME.find({\"likes\": {$gt:50}, $or: [{\"ASPD_Nm\":\"缘定三生炽热红25g（电子渠道）\", \"Co_Nm\":\"紫金矿\"}]}).pretty() 2. java代码查询mongo的数据postgresql中, 基金/ 保险/ 金条/ 贵金属表都有一个code对应mongo里的一条或多条数据 引依赖 org.springframework.boot spring-boot-starter-data-mongodb 以基金的详情查询为例: //创建查询对象Query query = new Query();Criteria criteria = new Criteria();//根据主键在postgresql中查询出当前查询的基金对象ProductFund fund = fundMapper.selectByPrimaryKey(productId);//使用query构建查询条件query = new Query(Criteria.where(\"code\").is(fund.getCode()));dataSet = \"fund_detail_data\";query.addCriteria(criteria);//用mongoTemplate的查询方法, 入参:查询条件对象query, 返回类型以及要查询的集合Map data = mongoTemplate.findOne(query, Map.class, dataSet);//拿到的data是map类型的结构, 列名对应内容. 与存入mongo里的bson类型一致. 结果data的结构(也是mongodb里存储的数据结构)如下所示: { \"_id\": ObjectId(\"5dfb71baf6f3fb2a9e1bfb69\"), \"ASPD_ID\": \"10279468\", \"ASPD_Nm\": \"百变小金猪（电子渠道）\", \"Acpt_Dntn_Inst_Nm\": \"\", \"AlSal_Ind\": \"1\", \"Ast_RcmdInf_Intd_Cmnt\": \"《百变小金猪》运用了猪元素与可爱表情相结合进行设计...\", \"AtchURL_Adr\": \"\", \"Br_Prmt_MtdCd\": \"\" ...} 如果在查询时排除一些字段, 可以: //eg: 返回结果过滤_id, Ins_PD_Trl_Cd字段query.fields().exclude(\"_id\");query.fields().exclude(\"Ins_PD_Trl_Cd\"); 增加一些查询的筛选条件, 可以: //eg: 只查PM_PD_ID等于贵金属的code的数据criteria.and(\"PM_PD_ID\").is(metal.getCode()); 3. mongo的分页与排序 分页: 分页可以使用默认的skip，limit关键字结合的方式来实现, 适用于中小数据量. //第一页db.COLLECTION_NAME.find().limit (10)//第二页db.COLLECTION_NAME.find().skip(10).limit(10)//第三页db.COLLECTION_NAME.find().skip(20).limit(10) 但是在查询时会扫描全表. 然后再返回结果. 解决的方法是: 可以先查出当前页第一条, 然后顺序数pageSize条 排序: db.students.find({ _id:{ $gt: startValue}}).sort({_id: 1})});1是升序, -1是降序","permalink":"https://shitianshuai1111.github.io/2017/04/25/MongoDB%E7%94%A8%E6%B3%95/","photos":[]},{"tags":[{"name":"笔记","slug":"笔记","permalink":"https://shitianshuai1111.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"业务","slug":"业务","permalink":"https://shitianshuai1111.github.io/tags/%E4%B8%9A%E5%8A%A1/"}],"title":"图片上传策略之OSS","date":"2017/03/31","text":"方式一:一. OSSOss对象存储的优势体现在: 本张图片就存放于七牛云上 二. 需求现在, 用户可以提交意见反馈给后台, 反馈的内容同时可携带多张图片. 我们不想在数据库中直接保存图片的base64格式的字符, 因为如果图片很大, 那么数据库负担很重. 所以我们使用oss对象存储服务 三. 实现实现的流程为 1. 输入表单用户输入完表单, 选择好了要上传的图片, 点击 提交反馈 发送请求 2. 前端发送图片上传的请求该请求需设置请求头Content-Type: multipart/form-data; 请求体为form-data的file类型, 同时可以选择多张要上传的图片 3. 同时, 后端Controller接收请求package com.macro.mall.portal.controller;import com.macro.mall.common.api.CommonResult;import com.macro.mall.portal.domain.ImagesFile;import com.macro.mall.portal.util.QiniuUtils;import io.swagger.annotations.Api;import io.swagger.annotations.ApiOperation;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.ResponseBody;import org.springframework.web.multipart.MultipartFile;import java.io.IOException;import java.io.InputStream;import java.util.ArrayList;import java.util.UUID;/** * 图片上传Controller * Created by goblin. */@Controller@Api(tags = \"UploadFileController\", description = \"图片上传\")@RequestMapping(\"/upload\")public class UploadFileController { /** * 上传图片 * @param multipartFiles * @return */ @ApiOperation(\"上传图片\") @RequestMapping(value = \"/images\", method = RequestMethod.POST) @ResponseBody public CommonResult upload(@RequestParam(\"imgFile\") MultipartFile[] multipartFiles) { ArrayList imgFile = new ArrayList(); for (MultipartFile multipartFile : multipartFiles) { ImagesFile imagesFile = new ImagesFile(); //原始文件名 String originalFileName = multipartFile.getOriginalFilename(); imagesFile.setImageName(originalFileName); //使用UUID构造不重复的文件名 String fileName = UUID.randomUUID().toString().replace(\"-\", \"\") + \".\" + getPicSuffix(originalFileName); //获取输入流并上传 try (InputStream is = multipartFile.getInputStream()) { QiniuUtils.upload2Qiniu(is, fileName); } catch (RuntimeException| IOException e) { CommonResult.failed(); } //构造返回值 String pic = QiniuUtils.QINIU_IMG_URL_PRE + fileName; imagesFile.setImageUrl(pic); imgFile.add(imagesFile); } return CommonResult.success(imgFile); } public static String getPicSuffix(String imgPath){ if (imgPath == null || imgPath.indexOf(\".\") == -1){ return \"\"; //如果图片地址为null或者地址中没有\".\"就返回\"\" } return imgPath.substring(imgPath.lastIndexOf(\".\") + 1). trim().toLowerCase(); }} 值得注意的是, 这里需要用注解@RequestParam(“参数名”) MultipartFile[] 来接收多张图片 multipartFile.getOriginalFilename();可以用来获取上传文件的名字以及后缀. 这里用到了七牛云上传工具类: package com.macro.mall.portal.util;import com.qiniu.common.QiniuException;import com.qiniu.http.Response;import com.qiniu.storage.BucketManager;import com.qiniu.storage.Configuration;import com.qiniu.storage.Region;import com.qiniu.storage.UploadManager;import com.qiniu.util.Auth;import lombok.extern.slf4j.Slf4j;import java.io.IOException;import java.io.InputStream;import java.util.Properties;/** * @author zhangmeng * @description 七牛云工具类 * @date 2019/9/26 **/@Slf4jpublic class QiniuUtils { public static final String CONFIG_FILE = \"qiniu-config.properties\"; public static String ACCESS_KEY; public static String SECRET_KEY; public static String QINIU_IMG_URL_PRE; public static String BUCKET; static { Properties prop = new Properties(); // 加载配置 try(InputStream is = QiniuUtils.class.getClassLoader().getResourceAsStream(\"qiniu-config.properties\")) { if(null == is){ log.error(\"[七牛云工具类-初始化]失败,请提供配置文件：{}\",CONFIG_FILE); }else { prop.load(is); } } catch (IOException e) { // 几乎不可能事件，直接转换为运行时异常继续上抛 throw new RuntimeException(e); } ACCESS_KEY = prop.getProperty(\"access.key\", \"\"); SECRET_KEY = prop.getProperty(\"secret.key\", \"\"); QINIU_IMG_URL_PRE = prop.getProperty(\"img.url.prefix\", \"\"); BUCKET = prop.getProperty(\"bucket\", \"\"); log.info(\"[七牛云工具类-初始化]完成\"); } /** * 上传到七牛云 * * @param is 上传内容的输入流 * @param uploadFileName */ public static void upload2Qiniu(InputStream is, String uploadFileName) throws QiniuException { //构造一个带指定Zone对象的配置类 Configuration cfg = new Configuration(Region.autoRegion()); //...其他参数参考类注释 UploadManager uploadManager = new UploadManager(cfg); //默认不指定key的情况下，以文件内容的hash值作为文件名 String key = uploadFileName; Auth auth = Auth.create(ACCESS_KEY, SECRET_KEY); String upToken = auth.uploadToken(BUCKET); try { Response response = uploadManager.put(is, key, upToken, null, null); //解析上传成功的结果 log.info(response.bodyString()); // 访问路径 log.info(\"{}/{}\", QINIU_IMG_URL_PRE, uploadFileName); } catch (QiniuException ex) { Response r = ex.response; log.error(r.toString()); try { log.error(r.bodyString()); } catch (QiniuException ex2) { //ignore log.error(\"\", ex2); } throw ex; } } public static void deleteFileFromQiniu(String fileName) throws QiniuException { //构造一个带指定Zone对象的配置类 Configuration cfg = new Configuration(Region.autoRegion()); String key = fileName; Auth auth = Auth.create(ACCESS_KEY, SECRET_KEY); BucketManager bucketManager = new BucketManager(auth, cfg); try { bucketManager.delete(BUCKET, key); } catch (QiniuException ex) { //如果遇到异常，说明删除失败 log.error(\"code:{}\", ex.code()); log.error(ex.response.toString()); throw ex; } }} 配置文件qiniu-config.properties在resource文件夹下 img.url.prefix=专属外链access.key=七牛云的AKsecret.key=七牛云的SKbucket=要上传到桶的名字 4. 前端收到结果{ \"code\": 200, \"message\": \"操作成功\", \"data\": [ { \"imageName\": \"timg (1).jpeg\", \"imageUrl\": \"http://q850xek50.bkt.clouddn.com/6ce55d289d8f499783d86771bbf2a074.jpeg\" }, { \"imageName\": \"timg (2).jpeg\", \"imageUrl\": \"http://q850xek50.bkt.clouddn.com/3deb81d57fa643c5ac9948d6ca72e59e.jpeg\" }, { \"imageName\": \"timg.jpeg\", \"imageUrl\": \"http://q850xek50.bkt.clouddn.com/327fa1b7964346588bdec1b28154e619.jpeg\" } ]} 5. 再次发送请求此时, 请求体中带着反馈的内容和图片的url等内容, 交由后端保存到数据库中. { \"feedback\": \" \", \"questionType\": \" \", \"images\": \" \" ...} 方式二:前端直接向阿里云OSS发送上传图片请求 Controller: package com.macro.mall.controller;import com.macro.mall.common.api.CommonResult;import com.macro.mall.dto.OssCallbackResult;import com.macro.mall.dto.OssPolicyResult;import com.macro.mall.service.impl.OssServiceImpl;import io.swagger.annotations.Api;import io.swagger.annotations.ApiOperation;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.*;import javax.servlet.http.HttpServletRequest;/** * Oss相关操作接口 * Created by macro on 2018/4/26. */@Controller@Api(tags = \"OssController\", description = \"Oss管理\")@RequestMapping(\"/aliyun/oss\")@CrossOriginpublic class OssController { @Autowired private OssServiceImpl ossService; @ApiOperation(value = \"oss上传签名生成\") @RequestMapping(value = \"/policy\", method = RequestMethod.GET) @ResponseBody public CommonResult policy() { OssPolicyResult result = ossService.policy(); return CommonResult.success(result); } @ApiOperation(value = \"oss上传成功回调\") @RequestMapping(value = \"callback\", method = RequestMethod.POST) @ResponseBody public CommonResult callback(HttpServletRequest request) { OssCallbackResult ossCallbackResult = ossService.callback(request); return CommonResult.success(ossCallbackResult); }} OssServiceImpl: 前端请求后台生成 许可 /** * 签名生成 */@Overridepublic OssPolicyResult policy() { OssPolicyResult result = new OssPolicyResult(); // 存储目录 SimpleDateFormat sdf = new SimpleDateFormat(\"yyyyMMdd\"); String dir = ALIYUN_OSS_DIR_PREFIX + sdf.format(new Date()); // 签名有效期 long expireEndTime = System.currentTimeMillis() + ALIYUN_OSS_EXPIRE * 1000; Date expiration = new Date(expireEndTime); // 文件大小 long maxSize = ALIYUN_OSS_MAX_SIZE * 1024 * 1024; // 回调 OssCallbackParam callback = new OssCallbackParam(); callback.setCallbackUrl(ALIYUN_OSS_CALLBACK); callback.setCallbackBody(\"filename=${object}&size=${size}&mimeType=${mimeType}&height=${imageInfo.height}&width=${imageInfo.width}\"); callback.setCallbackBodyType(\"application/x-www-form-urlencoded\"); // 提交节点 String action = \"http://\" + ALIYUN_OSS_BUCKET_NAME + \".\" + ALIYUN_OSS_ENDPOINT; try { PolicyConditions policyConds = new PolicyConditions(); policyConds.addConditionItem(PolicyConditions.COND_CONTENT_LENGTH_RANGE, 0, maxSize); policyConds.addConditionItem(MatchMode.StartWith, PolicyConditions.COND_KEY, dir); String postPolicy = ossClient.generatePostPolicy(expiration, policyConds); byte[] binaryData = postPolicy.getBytes(\"utf-8\"); String policy = BinaryUtil.toBase64String(binaryData); String signature = ossClient.calculatePostSignature(postPolicy); String callbackData = BinaryUtil.toBase64String(JSONUtil.parse(callback).toString().getBytes(\"utf-8\")); // 返回结果 result.setAccessKeyId(ossClient.getCredentialsProvider().getCredentials().getAccessKeyId()); result.setPolicy(policy); result.setSignature(signature); result.setDir(dir); result.setCallback(callbackData); result.setHost(action); } catch (Exception e) { LOGGER.error(\"签名生成失败\", e); } return result;} 配置文件: aliyun: oss: endpoint: # oss对外服务的访问域名 accessKeyId: # 访问身份验证中用到用户标识 accessKeySecret: # 用户用于加密签名字符串和oss用来验证签名字符串的密钥 bucketName: # oss的存储空间 policy: expire: 300 # 签名有效期(S) maxSize: 10 # 上传文件大小(M) callback: http://localhost:8080/aliyun/oss/callback # 文件上传成功后的回调地址 dir: prefix: mall/images/ # 上传文件夹路径前缀 阿里云上传成功后的回调函数 @Overridepublic OssCallbackResult callback(HttpServletRequest request) { OssCallbackResult result= new OssCallbackResult(); String filename = request.getParameter(\"filename\"); filename = \"http://\".concat(ALIYUN_OSS_BUCKET_NAME).concat(\".\").concat(ALIYUN_OSS_ENDPOINT).concat(\"/\").concat(filename); result.setFilename(filename); result.setSize(request.getParameter(\"size\")); result.setMimeType(request.getParameter(\"mimeType\")); result.setWidth(request.getParameter(\"width\")); result.setHeight(request.getParameter(\"height\")); return result;} 前端通过回调函数得到存储图片的url路径.","permalink":"https://shitianshuai1111.github.io/2017/03/31/%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0%E7%AD%96%E7%95%A5/","photos":[]},{"tags":[{"name":"笔记","slug":"笔记","permalink":"https://shitianshuai1111.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"业务","slug":"业务","permalink":"https://shitianshuai1111.github.io/tags/%E4%B8%9A%E5%8A%A1/"}],"title":"爬坑之路","date":"2017/03/31","text":"1. 实体类的生日是Date类型, 直接返回前端, 前端难处理使用注解: @JsonFormat(shape=JsonFormat.Shape.STRING,pattern=\"yyyy-MM-dd\",timezone=\"GMT+8\") private Date birthday; 就可在传给前端时, 格式化日期为: { \"code\": 200, \"message\": \"操作成功\", \"data\": { \"birthday\": \"2020-04-08\", }} 2. 根据经纬度计算距离 已有用户的经纬度和商家的经纬度, 通过mysql sql语句根据距离排序查询出所有商家, 并将计算出的距离返回. SQL语句如下: 参数含义locationX-用户经度 locationY-用户纬度 lng-数据库中商家经度 lat-数据库中商家纬度 将距离计算出, 别名distance和其他数据一起返回 SELECT DISTINCT *,( round(6371392.89 * acos ( cos ( radians(#{locationY,jdbcType=DECIMAL}) ) * cos( radians( lat ) ) * cos( radians( lng ) - radians(#{locationX,jdbcType=DECIMAL}) ) + sin ( radians(#{locationY,jdbcType=DECIMAL}) ) * sin( radians( lat ) ) ),2 ) )AS distance FROM yd_shop ORDER BY distance 经测试 误差与百度地图计算距离控制在三十米之内. 3. 新增代码与mybatis逆向工程冲突问题 新增的代码会被mybatis逆向工程覆盖, 如果配置关闭覆盖, 那么以后对该表做改动的时候又要重写新增的部分. 解决: 将新增的内容, 写在新建Dao中, 令xml文件继承源mapper.xml, 这样新增内容时, 就不担心被覆盖了. SELECT DISTINCT *,( round(6371392.89 * acos ( cos ( radians(#{locationY,jdbcType=DECIMAL}) ) * cos( radians( lat ) ) * cos( radians( lng ) - radians(#{locationX,jdbcType=DECIMAL}) ) + sin ( radians(#{locationY,jdbcType=DECIMAL}) ) * sin( radians( lat ) ) ),2 ) )AS distance FROM yd_shop ORDER BY distance 4. 阿里云发送短信工具类: package com.macro.mall.portal.util;import com.aliyuncs.CommonRequest;import com.aliyuncs.CommonResponse;import com.aliyuncs.DefaultAcsClient;import com.aliyuncs.IAcsClient;import com.aliyuncs.exceptions.ClientException;import com.aliyuncs.http.MethodType;import com.aliyuncs.profile.DefaultProfile;import lombok.extern.slf4j.Slf4j;import java.io.IOException;import java.io.InputStream;import java.util.Properties;/** * @description 阿里云短信工具类 * @author goblin * @date 2020-04-14 **/@Slf4jpublic class AliMessageUtils { public static final String CONFIG_FILE = \"rabbitmq-message.properties\"; public static String REGION_ID; public static String ACCESS_KEY_ID; public static String ACCESS_KEY_SECRET; public static String SIGN_NAME; public static String TEMPLATE_CODE; static { Properties prop = new Properties(); // 加载配置 try (InputStream is = QiniuUtils.class.getClassLoader().getResourceAsStream(\"rabbitmq-message.properties\")) { if (null == is) { log.error(\"[阿里云短信工具类-初始化]失败,请提供配置文件：{}\", CONFIG_FILE); } else { prop.load(is); } } catch (IOException e) { // 几乎不可能事件，直接转换为运行时异常继续上抛 throw new RuntimeException(e); } REGION_ID = prop.getProperty(\"region.id\", \"\"); ACCESS_KEY_ID = prop.getProperty(\"access.key.id\", \"\"); ACCESS_KEY_SECRET = prop.getProperty(\"access.key.secret\", \"\"); SIGN_NAME = prop.getProperty(\"sign.name\", \"\"); TEMPLATE_CODE = prop.getProperty(\"template.code\", \"\"); log.info(\"[阿里云工具类-初始化]完成\"); } //发送短信 public static void sendSMS(String phone, String code) { DefaultProfile profile = DefaultProfile.getProfile(REGION_ID, ACCESS_KEY_ID, ACCESS_KEY_SECRET); IAcsClient client = new DefaultAcsClient(profile); //拼接模板参数（验证码）value Json格式字符串 //您本次的验证码为：${code}，本验证码仅在5分钟内有效, 请勿告知他人, 如果不是您本人操作. 请忽略此信息. 欢迎您的加入! String codeSMS = \"{\\\"code\\\":\\\"\" + code + \"\\\"}\"; CommonRequest request = new CommonRequest(); request.setMethod(MethodType.POST); request.setDomain(\"dysmsapi.aliyuncs.com\"); request.setVersion(\"2017-05-25\"); request.setAction(\"SendSms\"); request.putQueryParameter(\"RegionId\", REGION_ID); request.putQueryParameter(\"PhoneNumbers\", phone); request.putQueryParameter(\"SignName\", SIGN_NAME); request.putQueryParameter(\"TemplateCode\", TEMPLATE_CODE); request.putQueryParameter(\"TemplateParam\", codeSMS); try { CommonResponse response = client.getCommonResponse(request); System.out.println(response.getData()); } catch (ClientException e) { e.printStackTrace(); } }} 配置文件 rabbitmq-message.properties #地区region.id=cn-hangzhou#access.key.idaccess.key.id=access.key.id#access.key.secretaccess.key.secret=access.key.secret#签名sign.name=签名#短信模板template.code=短信模板 ####5. 使用@Valid+BindingResult进行controller参数校验 场景: 做后台的修改等操作时, 我们需要在后台验证传入的表单是否正确, 因为前端的验证可能是由postman等代发的, 前端表单校验不能保证绝对安全. 通常我们会定义一个要接收表单的实体类, 这里给出一个例子, 是品牌相关的类 PmsBrandParam: package com.macro.mall.dto;import com.macro.mall.validator.FlagValidator;import io.swagger.annotations.ApiModelProperty;import javax.validation.constraints.Min;import javax.validation.constraints.NotEmpty;/** * 品牌传递参数 * Created by goblin. */public class PmsBrandParam { @NotEmpty(message = \"名称不能为空\") private String name; @Min(value = 0, message = \"排序最小为0\") private Integer sort; @FlagValidator(value = {\"0\",\"1\"}, message = \"厂家状态不正确\") private Integer factoryStatus; @FlagValidator(value = {\"0\",\"1\"}, message = \"显示状态不正确\") private Integer showStatus; @NotEmpty(message = \"品牌logo不能为空\") private String logo; } 这里省略了部分字段, 通常这些子弹都是与数据库所需字段一一对应的, 我们要保存一个新数据时, 通过这个参数类保证数据正确. 再来看一下Controller: (这里的BindingResult, 会在下文介绍) @ApiOperation(value = \"更新品牌\") //SWAGGER@RequestMapping(value = \"/update/{id}\", method = RequestMethod.POST)@ResponseBodypublic CommonResult update(@PathVariable(\"id\") Long id, @Validated @RequestBody PmsBrandParam pmsBrandParam, BindingResult result) { CommonResult commonResult; int count = brandService.updateBrand(id, pmsBrandParam); if (count == 1) { commonResult = CommonResult.success(count); } else { commonResult = CommonResult.failed(); } return commonResult;} 在PmsBrandParam类的前面, 用到了@Validated注解, 这个注解的作用是提醒Spring Validation验证框架对参数进行验证. 其实除了@Validated, 还有一个注解很常见, @Valid. 那么什么时候使用这两个注解呢? 这就需要先了解这二者的不同. @Validated支持分组功能, 可以在入参验证时, 根据不同的分组采用不同的验证机制. 而@Valid不支持 @Validated可以注解在方法, 构造函数, 方法参数上, @Valid在此基础上, 还可以注解在成员属性(字段)上 留意一下这个区别, 因为这直接影响是否支持嵌套验证的功能, 下面会详细解释 所谓嵌套循环, 指的是我们的PmsBrandParam中, 如果有一个成员变量是另一个实体类型, 而他的成员变量同样需要进行校验, 那么, 因为@Validated无法注释在该实体类上, 所以不能仅通过@Validated实现嵌套的校验. 可行的方法为: package com.macro.mall.dto;import com.macro.mall.validator.FlagValidator;import io.swagger.annotations.ApiModelProperty;import javax.validation.constraints.Min;import javax.validation.constraints.NotEmpty;/** * 品牌传递参数 * Created by goblin. */public class PmsBrandParam { @NotEmpty(message = \"名称不能为空\") private String name; @Min(value = 0, message = \"排序最小为0\") private Integer sort; @FlagValidator(value = {\"0\",\"1\"}, message = \"厂家状态不正确\") private Integer factoryStatus; @FlagValidator(value = {\"0\",\"1\"}, message = \"显示状态不正确\") private Integer showStatus; @NotEmpty(message = \"品牌logo不能为空\") private String logo; @Valid // 嵌套验证必须用@Valid @NotNull(message = \"shops不能为空\") @Size(min = 1, message = \"props至少要有一个自定义属性\") private List shops; } 注意观察最后一个字段shops, 他上面因为使用了@Valid注解, 在校验时, 会同时验证他里面的字段. 我们这里给出一个YdShop的例子, 方便理解: public class YdShop { @NotNull(message = \"id不能为空\") @Min(value = 1, message = \"id必须为正整数\") private Long id; @NotBlank(message = \"name不能为空\") private String name;} #####5.1 常用注解校验 常用校验注解:@Null 只能是null@NotNull 不能为null 注意用在基本类型上无效，基本类型有默认初始值@AssertFalse 必须为false@AssertTrue 必须是true字符串/数组/集合检查：(字符串本身就是个数组)@Pattern(regexp=\"reg\") 验证字符串满足正则@Size(max, min) 验证字符串、数组、集合长度范围@NotEmpty 验证字符串不为空或者null@NotBlank 验证字符串不为null或者trim()后不为空数值检查：同时能验证一个字符串是否是满足限制的数字的字符串@Max 规定值得上限int@Min 规定值得下限@DecimalMax(\"10.8\") 以传入字符串构建一个BigDecimal，规定值要小于这个值 @DecimalMin 可以用来限制浮点数大小@Digits(int1, int2) 限制一个小数，整数精度小于int1；小数部分精度小于int2@Digits 无参数，验证字符串是否合法@Range(min=long1,max=long2) 检查数字是否在范围之间这些都包括边界值日期检查：Date/Calendar@Post 限定一个日期，日期必须是过去的日期@Future 限定一个日期，日期必须是未来的日期其他验证：@Vaild 递归验证，用于对象、数组和集合，会对对象的元素、数组的元素进行一一校验@Email 用于验证一个字符串是否是一个合法的右键地址，空字符串或null算验证通过@URL(protocol=,host=,port=,regexp=,flags=) 用于校验一个字符串是否是合法UR 5.2 BindingResult","permalink":"https://shitianshuai1111.github.io/2017/03/31/%E7%88%AC%E5%9D%91/","photos":[]}],"categories":[],"tags":[{"name":"软件","slug":"软件","permalink":"https://shitianshuai1111.github.io/tags/%E8%BD%AF%E4%BB%B6/"},{"name":"破解","slug":"破解","permalink":"https://shitianshuai1111.github.io/tags/%E7%A0%B4%E8%A7%A3/"},{"name":"笔记","slug":"笔记","permalink":"https://shitianshuai1111.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"命令行","slug":"命令行","permalink":"https://shitianshuai1111.github.io/tags/%E5%91%BD%E4%BB%A4%E8%A1%8C/"},{"name":"干货","slug":"干货","permalink":"https://shitianshuai1111.github.io/tags/%E5%B9%B2%E8%B4%A7/"},{"name":"业务","slug":"业务","permalink":"https://shitianshuai1111.github.io/tags/%E4%B8%9A%E5%8A%A1/"}]}